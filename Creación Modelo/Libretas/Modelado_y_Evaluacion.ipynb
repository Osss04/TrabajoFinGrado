{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038dceed",
   "metadata": {
    "papermill": {
     "duration": 0.009972,
     "end_time": "2025-05-27T04:28:35.484506",
     "exception": false,
     "start_time": "2025-05-27T04:28:35.474534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>Técnicas Avanzadas de Aprendizaje Automático para la Detección de Intrusos en Sistemas Ciber-Físicos: Modelado y Evaluación</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe49af4",
   "metadata": {
    "papermill": {
     "duration": 0.008252,
     "end_time": "2025-05-27T04:28:35.501459",
     "exception": false,
     "start_time": "2025-05-27T04:28:35.493207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Introducción</h2>\n",
    "\n",
    "En esta libreta se crea el modelo correspondiente usando los resultados obtenidos de la libreta `Análisis_y_Preprocesamiento_de_los_Datos.ipynb`.  Concretamente, se explican las siguientes fases de la metodología **CRISP-DM**:\n",
    "\n",
    "- **Modelado**: Se elige el algoritmo de aprendizaje más adecuado, se realiza la búsqueda de los mejores hiperparámetros y se entrena.\n",
    "- **Evaluación**: Se evalúan los resultados que ofrece el modelo entrenado en fucnión de los objetivos establecidos en la comprensión del negocio.\n",
    "\n",
    "Los contenidos que se tratarán en esta libreta son los siguientes:\n",
    "\n",
    "1. **Cargar los datos preprocesados**. Se cargan los resultados obtenidos de la libreta `Análisis_y_Preprocesamiento_de_los_Datos.ipynb`.\n",
    "2. **Creación del modelo**. Pertenece a la fase de Modelado.\n",
    "3. **Evaluación del modelo**. Pertenece a la fase de Evaluación.\n",
    "4. **Exportar resultados**. Se guardan los resultados obtenidos.\n",
    "\n",
    "\n",
    "Se han seguido los pasos que se establecen en el artículo: **MADICS: A Methodology for Anomaly Detectionin Industrial Control Systems**, aunque tenía algunos fallos a nivel académico y han sido eliminados y solucionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551c1fa",
   "metadata": {
    "papermill": {
     "duration": 0.008401,
     "end_time": "2025-05-27T04:28:35.518295",
     "exception": false,
     "start_time": "2025-05-27T04:28:35.509894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>1. Cargar los datos preprocesados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36544783",
   "metadata": {
    "papermill": {
     "duration": 0.008262,
     "end_time": "2025-05-27T04:28:35.535490",
     "exception": false,
     "start_time": "2025-05-27T04:28:35.527228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "En esta sección se cargan los .csv que han sido generados en la libreta anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b026cc",
   "metadata": {
    "papermill": {
     "duration": 1.482763,
     "end_time": "2025-05-27T04:28:37.026754",
     "exception": false,
     "start_time": "2025-05-27T04:28:35.543991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed1416c",
   "metadata": {
    "papermill": {
     "duration": 3.203565,
     "end_time": "2025-05-27T04:28:40.239554",
     "exception": false,
     "start_time": "2025-05-27T04:28:37.035989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f005e54e",
   "metadata": {
    "papermill": {
     "duration": 0.824086,
     "end_time": "2025-05-27T04:28:41.074392",
     "exception": false,
     "start_time": "2025-05-27T04:28:40.250306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = pd.read_csv(\"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bf07f2",
   "metadata": {
    "papermill": {
     "duration": 3.395757,
     "end_time": "2025-05-27T04:28:44.479012",
     "exception": false,
     "start_time": "2025-05-27T04:28:41.083255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888884a1",
   "metadata": {
    "papermill": {
     "duration": 0.008508,
     "end_time": "2025-05-27T04:28:44.499725",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.491217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se comprueba si los datos se han cargado de manera correcta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316c99fe",
   "metadata": {
    "papermill": {
     "duration": 0.121405,
     "end_time": "2025-05-27T04:28:44.629506",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.508101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>std_FIT101_120</th>\n",
       "      <th>std_LIT101_120</th>\n",
       "      <th>std_FIT201_120</th>\n",
       "      <th>...</th>\n",
       "      <th>MV303_1</th>\n",
       "      <th>MV303_2</th>\n",
       "      <th>MV304_0</th>\n",
       "      <th>MV304_1</th>\n",
       "      <th>MV304_2</th>\n",
       "      <th>P302_1</th>\n",
       "      <th>P302_2</th>\n",
       "      <th>P602_1</th>\n",
       "      <th>P602_2</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.894061</td>\n",
       "      <td>0.145253</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>0.817110</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888111</td>\n",
       "      <td>0.144064</td>\n",
       "      <td>0.981095</td>\n",
       "      <td>0.965737</td>\n",
       "      <td>0.818515</td>\n",
       "      <td>0.966238</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884144</td>\n",
       "      <td>0.144540</td>\n",
       "      <td>0.981095</td>\n",
       "      <td>0.964336</td>\n",
       "      <td>0.822205</td>\n",
       "      <td>0.965394</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883677</td>\n",
       "      <td>0.143826</td>\n",
       "      <td>0.981095</td>\n",
       "      <td>0.964336</td>\n",
       "      <td>0.823259</td>\n",
       "      <td>0.965225</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.884611</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>0.981095</td>\n",
       "      <td>0.964959</td>\n",
       "      <td>0.824313</td>\n",
       "      <td>0.966069</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>0.969320</td>\n",
       "      <td>0.057625</td>\n",
       "      <td>0.240040</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911708</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701285</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.969320</td>\n",
       "      <td>0.057273</td>\n",
       "      <td>0.239534</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913510</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699857</td>\n",
       "      <td>0.989646</td>\n",
       "      <td>0.969320</td>\n",
       "      <td>0.056395</td>\n",
       "      <td>0.241222</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915023</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698549</td>\n",
       "      <td>0.989749</td>\n",
       "      <td>0.969320</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916826</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696883</td>\n",
       "      <td>0.989749</td>\n",
       "      <td>0.969320</td>\n",
       "      <td>0.057625</td>\n",
       "      <td>0.242572</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918668</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101    FIT201   DPIT301    LIT301    LIT401    FIT601  \\\n",
       "0       0.894061  0.145253  0.980632  0.966672  0.817110  0.964381  0.000037   \n",
       "1       0.888111  0.144064  0.981095  0.965737  0.818515  0.966238  0.000037   \n",
       "2       0.884144  0.144540  0.981095  0.964336  0.822205  0.965394  0.000037   \n",
       "3       0.883677  0.143826  0.981095  0.964336  0.823259  0.965225  0.000037   \n",
       "4       0.884611  0.143112  0.981095  0.964959  0.824313  0.966069  0.000037   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "295995  0.000000  0.701880  0.988616  0.969320  0.057625  0.240040  0.000037   \n",
       "295996  0.000000  0.701285  0.989337  0.969320  0.057273  0.239534  0.000037   \n",
       "295997  0.000000  0.699857  0.989646  0.969320  0.056395  0.241222  0.000037   \n",
       "295998  0.000000  0.698549  0.989749  0.969320  0.057800  0.240547  0.000037   \n",
       "295999  0.000000  0.696883  0.989749  0.969320  0.057625  0.242572  0.000037   \n",
       "\n",
       "        std_FIT101_120  std_LIT101_120  std_FIT201_120  ...  MV303_1  MV303_2  \\\n",
       "0                  0.0        0.000000        0.000000  ...      1.0      0.0   \n",
       "1                  0.0        0.000000        0.000000  ...      1.0      0.0   \n",
       "2                  0.0        0.000000        0.000000  ...      1.0      0.0   \n",
       "3                  0.0        0.000000        0.000000  ...      1.0      0.0   \n",
       "4                  0.0        0.000000        0.000000  ...      1.0      0.0   \n",
       "...                ...             ...             ...  ...      ...      ...   \n",
       "295995             0.0        0.911708        0.001927  ...      1.0      0.0   \n",
       "295996             0.0        0.913510        0.001909  ...      1.0      0.0   \n",
       "295997             0.0        0.915023        0.001897  ...      1.0      0.0   \n",
       "295998             0.0        0.916826        0.001889  ...      1.0      0.0   \n",
       "295999             0.0        0.918668        0.001879  ...      1.0      0.0   \n",
       "\n",
       "        MV304_0  MV304_1  MV304_2  P302_1  P302_2  P602_1  P602_2  \\\n",
       "0           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "1           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "2           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "3           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "4           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "...         ...      ...      ...     ...     ...     ...     ...   \n",
       "295995      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "295996      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "295997      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "295998      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "295999      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "\n",
       "        Normal/Attack  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "295995              0  \n",
       "295996              0  \n",
       "295997              0  \n",
       "295998              0  \n",
       "295999              0  \n",
       "\n",
       "[296000 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82cf639",
   "metadata": {
    "papermill": {
     "duration": 0.051805,
     "end_time": "2025-05-27T04:28:44.690732",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.638927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>std_FIT101_120</th>\n",
       "      <th>std_LIT101_120</th>\n",
       "      <th>std_FIT201_120</th>\n",
       "      <th>...</th>\n",
       "      <th>MV303_1</th>\n",
       "      <th>MV303_2</th>\n",
       "      <th>MV304_0</th>\n",
       "      <th>MV304_1</th>\n",
       "      <th>MV304_2</th>\n",
       "      <th>P302_1</th>\n",
       "      <th>P302_2</th>\n",
       "      <th>P602_1</th>\n",
       "      <th>P602_2</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695099</td>\n",
       "      <td>0.989594</td>\n",
       "      <td>0.965893</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.240209</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692482</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.968229</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.241391</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690221</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.968541</td>\n",
       "      <td>0.055341</td>\n",
       "      <td>0.240378</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688913</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.968541</td>\n",
       "      <td>0.055341</td>\n",
       "      <td>0.241897</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687247</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.970565</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>0.241897</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98995</th>\n",
       "      <td>0.896278</td>\n",
       "      <td>0.110992</td>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.742444</td>\n",
       "      <td>0.731937</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.062149</td>\n",
       "      <td>0.071088</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98996</th>\n",
       "      <td>0.892078</td>\n",
       "      <td>0.110754</td>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.742795</td>\n",
       "      <td>0.732612</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.061966</td>\n",
       "      <td>0.071199</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98997</th>\n",
       "      <td>0.886944</td>\n",
       "      <td>0.110516</td>\n",
       "      <td>0.982743</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.743147</td>\n",
       "      <td>0.733456</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.071265</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98998</th>\n",
       "      <td>0.884611</td>\n",
       "      <td>0.110635</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.744201</td>\n",
       "      <td>0.732443</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.071426</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98999</th>\n",
       "      <td>0.884144</td>\n",
       "      <td>0.110397</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.744025</td>\n",
       "      <td>0.732950</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.062490</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FIT101    LIT101    FIT201   DPIT301    LIT301    LIT401    FIT601  \\\n",
       "0      0.000000  0.695099  0.989594  0.965893  0.055868  0.240209  0.000037   \n",
       "1      0.000000  0.692482  0.989337  0.968229  0.054287  0.241391  0.000037   \n",
       "2      0.000000  0.690221  0.989337  0.968541  0.055341  0.240378  0.000037   \n",
       "3      0.000000  0.688913  0.989337  0.968541  0.055341  0.241897  0.000037   \n",
       "4      0.000000  0.687247  0.989337  0.970565  0.056219  0.241897  0.000037   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "98995  0.896278  0.110992  0.981713  0.960754  0.742444  0.731937  0.000073   \n",
       "98996  0.892078  0.110754  0.981713  0.960754  0.742795  0.732612  0.000073   \n",
       "98997  0.886944  0.110516  0.982743  0.960754  0.743147  0.733456  0.000073   \n",
       "98998  0.884611  0.110635  0.982949  0.960754  0.744201  0.732443  0.000073   \n",
       "98999  0.884144  0.110397  0.982949  0.960754  0.744025  0.732950  0.000073   \n",
       "\n",
       "       std_FIT101_120  std_LIT101_120  std_FIT201_120  ...  MV303_1  MV303_2  \\\n",
       "0            0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "1            0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "2            0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "3            0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "4            0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "...               ...             ...             ...  ...      ...      ...   \n",
       "98995        0.062149        0.071088        0.001501  ...      1.0      0.0   \n",
       "98996        0.061966        0.071199        0.001490  ...      1.0      0.0   \n",
       "98997        0.062001        0.071265        0.001493  ...      1.0      0.0   \n",
       "98998        0.062238        0.071426        0.001501  ...      1.0      0.0   \n",
       "98999        0.062490        0.071516        0.001508  ...      1.0      0.0   \n",
       "\n",
       "       MV304_0  MV304_1  MV304_2  P302_1  P302_2  P602_1  P602_2  \\\n",
       "0          0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "1          0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "2          0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "3          0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "4          0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "...        ...      ...      ...     ...     ...     ...     ...   \n",
       "98995      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "98996      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "98997      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "98998      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "98999      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "\n",
       "       Normal/Attack  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "98995              0  \n",
       "98996              0  \n",
       "98997              0  \n",
       "98998              0  \n",
       "98999              0  \n",
       "\n",
       "[99000 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244baf05",
   "metadata": {
    "papermill": {
     "duration": 0.154536,
     "end_time": "2025-05-27T04:28:44.862833",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.708297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>std_FIT101_120</th>\n",
       "      <th>std_LIT101_120</th>\n",
       "      <th>std_FIT201_120</th>\n",
       "      <th>...</th>\n",
       "      <th>MV303_1</th>\n",
       "      <th>MV303_2</th>\n",
       "      <th>MV304_0</th>\n",
       "      <th>MV304_1</th>\n",
       "      <th>MV304_2</th>\n",
       "      <th>P302_1</th>\n",
       "      <th>P302_2</th>\n",
       "      <th>P602_1</th>\n",
       "      <th>P602_2</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884144</td>\n",
       "      <td>0.110397</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.744025</td>\n",
       "      <td>0.732950</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891145</td>\n",
       "      <td>0.110516</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.744025</td>\n",
       "      <td>0.732781</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906779</td>\n",
       "      <td>0.110397</td>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.957951</td>\n",
       "      <td>0.745431</td>\n",
       "      <td>0.732106</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923230</td>\n",
       "      <td>0.110754</td>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.957951</td>\n",
       "      <td>0.746836</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935947</td>\n",
       "      <td>0.112301</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.957951</td>\n",
       "      <td>0.748066</td>\n",
       "      <td>0.733625</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449914</th>\n",
       "      <td>0.932563</td>\n",
       "      <td>0.100404</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>0.824664</td>\n",
       "      <td>0.797940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063371</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449915</th>\n",
       "      <td>0.928596</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>0.824840</td>\n",
       "      <td>0.799290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.059587</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449916</th>\n",
       "      <td>0.922179</td>\n",
       "      <td>0.103854</td>\n",
       "      <td>0.988873</td>\n",
       "      <td>0.989099</td>\n",
       "      <td>0.823435</td>\n",
       "      <td>0.799796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063258</td>\n",
       "      <td>0.060898</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449917</th>\n",
       "      <td>0.918446</td>\n",
       "      <td>0.103973</td>\n",
       "      <td>0.988873</td>\n",
       "      <td>0.987385</td>\n",
       "      <td>0.823259</td>\n",
       "      <td>0.801484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063259</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449918</th>\n",
       "      <td>0.911329</td>\n",
       "      <td>0.105163</td>\n",
       "      <td>0.988100</td>\n",
       "      <td>0.986918</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.801822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063169</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449919 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101    FIT201   DPIT301    LIT301    LIT401    FIT601  \\\n",
       "0       0.884144  0.110397  0.982949  0.960754  0.744025  0.732950  0.000073   \n",
       "1       0.891145  0.110516  0.982949  0.960754  0.744025  0.732781  0.000073   \n",
       "2       0.906779  0.110397  0.981713  0.957951  0.745431  0.732106  0.000073   \n",
       "3       0.923230  0.110754  0.981713  0.957951  0.746836  0.731768  0.000073   \n",
       "4       0.935947  0.112301  0.982022  0.957951  0.748066  0.733625  0.000073   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449914  0.932563  0.100404  0.988616  0.992369  0.824664  0.797940  0.000000   \n",
       "449915  0.928596  0.103022  0.988616  0.992369  0.824840  0.799290  0.000000   \n",
       "449916  0.922179  0.103854  0.988873  0.989099  0.823435  0.799796  0.000000   \n",
       "449917  0.918446  0.103973  0.988873  0.987385  0.823259  0.801484  0.000000   \n",
       "449918  0.911329  0.105163  0.988100  0.986918  0.824137  0.801822  0.000000   \n",
       "\n",
       "        std_FIT101_120  std_LIT101_120  std_FIT201_120  ...  MV303_1  MV303_2  \\\n",
       "0             0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "1             0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "2             0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "3             0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "4             0.000000        0.000000        0.000000  ...      1.0      0.0   \n",
       "...                ...             ...             ...  ...      ...      ...   \n",
       "449914        0.063371        0.058520        0.001667  ...      1.0      0.0   \n",
       "449915        0.063253        0.059587        0.001660  ...      1.0      0.0   \n",
       "449916        0.063258        0.060898        0.001654  ...      1.0      0.0   \n",
       "449917        0.063259        0.062191        0.001647  ...      1.0      0.0   \n",
       "449918        0.063169        0.063797        0.001641  ...      1.0      0.0   \n",
       "\n",
       "        MV304_0  MV304_1  MV304_2  P302_1  P302_2  P602_1  P602_2  \\\n",
       "0           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "1           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "2           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "3           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "4           0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "...         ...      ...      ...     ...     ...     ...     ...   \n",
       "449914      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "449915      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "449916      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "449917      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "449918      0.0      1.0      0.0     0.0     1.0     1.0     0.0   \n",
       "\n",
       "        Normal/Attack  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "449914              0  \n",
       "449915              0  \n",
       "449916              0  \n",
       "449917              0  \n",
       "449918              0  \n",
       "\n",
       "[449919 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8deec",
   "metadata": {
    "papermill": {
     "duration": 0.017535,
     "end_time": "2025-05-27T04:28:44.892061",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.874526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>1.1. División de los datos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b107ca",
   "metadata": {
    "papermill": {
     "duration": 0.009279,
     "end_time": "2025-05-27T04:28:44.918506",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.909227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se dividen los datos en función de si se trata de la variable clase o las variables predictoras::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ffc7c2",
   "metadata": {
    "papermill": {
     "duration": 0.050404,
     "end_time": "2025-05-27T04:28:44.978218",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.927814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = \"Normal/Attack\")\n",
    "y_train = train[\"Normal/Attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffc41c3",
   "metadata": {
    "papermill": {
     "duration": 0.071381,
     "end_time": "2025-05-27T04:28:45.059492",
     "exception": false,
     "start_time": "2025-05-27T04:28:44.988111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_validation = validation.drop(columns = \"Normal/Attack\")\n",
    "y_validation = validation[\"Normal/Attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfa14d6",
   "metadata": {
    "papermill": {
     "duration": 0.062902,
     "end_time": "2025-05-27T04:28:45.138724",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.075822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test.drop(columns = \"Normal/Attack\")\n",
    "y_test = test[\"Normal/Attack\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73df1d",
   "metadata": {
    "papermill": {
     "duration": 0.017453,
     "end_time": "2025-05-27T04:28:45.174713",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.157260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>2. Creación del modelo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c409f",
   "metadata": {
    "papermill": {
     "duration": 0.009261,
     "end_time": "2025-05-27T04:28:45.198344",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.189083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "En esta sección se explcia el modelo que hemos elegido (con su correspondiente justificación) debido a la naturaleza del problema y se desarrolla paso a paso:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b417e54",
   "metadata": {
    "papermill": {
     "duration": 0.009256,
     "end_time": "2025-05-27T04:28:45.216915",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.207659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>2.1. Elegir el modelo</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e582e60",
   "metadata": {
    "papermill": {
     "duration": 0.009146,
     "end_time": "2025-05-27T04:28:45.235364",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.226218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Para los problemas de detección de anomalías, se recomienda utilizar un modelo de regresión de Deep Learning aplicado a una ventana W porque:\n",
    "\n",
    "- Modela comportamientos más complejos que el Machine Learning.\n",
    "- Se adecúa perfectamente a modelar datos de series temporales.\n",
    "\n",
    "En cuanto al tipo de problema, se debe optar por regresión en vez de clasificación debido a:\n",
    "\n",
    "- Señales y sensores de ICS siguen un patrón temporal fácilmente modeable por un regresor.\n",
    "- Adoptar un modelo de regresión junto a un umbral de anomalía genera información sobre el sensor que la causa, favoreciendo el diagnóstico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9024a",
   "metadata": {
    "papermill": {
     "duration": 0.01064,
     "end_time": "2025-05-27T04:28:45.255344",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.244704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "En cuanto al diseño del modelo, este recibirá una serie temporal con este formato: $\n",
    "(x_{0}, x_{1}, \\dots, x_{n-1})\n",
    "$.  A su vez,  $(y_{n+h}, \\dots, y_{n+h+m})$ es la salida del modelo, dónde n es la longitud de la ventana, m es número de predicciones futuras a realizar, h es el horizonte de predicción.\n",
    "\n",
    "Para configurar los hiperparámetros relacionados con los datos de entrada se debe tener en cuenta:\n",
    "\n",
    "- **n**: La ventana debe ser lo suficientemente grande para capturar el comportamiento del sistema. Se recomienda graficar las características para observar comportamientos repetitivos.\n",
    "- **h**: El horizonte de predicción especifica el paso de tiempo en el futuro a partir del cual el modelo comienza a predecir. Se sugiere probar diferentes valores para verificar que el modelo de Deep Learning está generalizando, en vez de replicar el último valor de entrada.\n",
    "- **m**: El número de pasos de tiempo predichos debe ajustarse según el escenario específico. En general, este valor se establecerá en uno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22982ebb",
   "metadata": {
    "papermill": {
     "duration": 0.009167,
     "end_time": "2025-05-27T04:28:45.273898",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.264731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Para implementar el modelo, se usará la libería **pytorch**. Para cargar los datos, se debe usar un dataset de la misma librería, por lo que se crea una clase personalizada para el dataset. En esta clase, se implementa un método que devuelve lotes de datos (para no tener mucha información a la vez en memoria) en tuplas x e y, representando series temporales hasta hasta $(y_{n+h}, \\dots, y_{n+h+m})$:.\n",
    "\n",
    "Primero, se añaden al código las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d39885d",
   "metadata": {
    "papermill": {
     "duration": 4.060812,
     "end_time": "2025-05-27T04:28:49.344300",
     "exception": false,
     "start_time": "2025-05-27T04:28:45.283488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a330af",
   "metadata": {
    "papermill": {
     "duration": 0.009243,
     "end_time": "2025-05-27T04:28:49.363603",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.354360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Posteriormente se crea la clase personaliza de datos llamada **TimeSeriesDataset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2936a8",
   "metadata": {
    "papermill": {
     "duration": 0.017555,
     "end_time": "2025-05-27T04:28:49.390453",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.372898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, n, h, m, overlap = 1):\n",
    "        \"\"\"\n",
    "        Parámetros:\n",
    "            data: Serie temporal, es un DataFrame.\n",
    "            n: Tamaño de la ventana, es un entero.\n",
    "            h: Horizonte de predicción, es un entero.\n",
    "            m: Número de predicciones futuras, es un entero.\n",
    "            overlap: es el solapamiento. Como para cada segundo se requieren\n",
    "            los 120 segundos anteriores, se usa el overlap para no pasar de 120 en 120. \n",
    "            Por defecto, su valor es 1.\n",
    "        \"\"\"\n",
    "\n",
    "        #convertir a float32 para que el entrenamiento sea más rápido\n",
    "        if isinstance(data, np.ndarray):\n",
    "            self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        else:\n",
    "            self.data = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "        self.n = n\n",
    "        self.h = h\n",
    "        self.m = m\n",
    "        self.overlap = overlap\n",
    "        \n",
    "        #cantidad de muestras posibles del dataset\n",
    "        self.num_samples = (len(self.data) - (n + h + m) + 1)// self.overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        getitem: Devuelve la muestra correspondiente al índice dado.\n",
    "\n",
    "        Devuelve:\n",
    "            - x: ventana de tamaño n.\n",
    "            - y: un valor futuro después de un horizonte h (tamaño 1).\n",
    "        \"\"\"\n",
    "        real_idx = idx*self.overlap\n",
    "        #ventana de entrada de tamaño n, con lo que se entrena\n",
    "        x = self.data[real_idx:real_idx+self.n]\n",
    "\n",
    "        #se quiere predecir el valor[n+m+h], por lo que se compara con el real\n",
    "        y = self.data[real_idx+self.n+self.h:real_idx+self.n+self.h+self.m].reshape(-1)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b301d",
   "metadata": {
    "papermill": {
     "duration": 0.009228,
     "end_time": "2025-05-27T04:28:49.409061",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.399833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A continuación, se configuran los hiperparámetros de los datos de entrada y se dejan preparados los generadores de datos. Se usan los siguientes hiperparámetros:\n",
    "\n",
    "- **n = 120**: Con una ventana de 120 segundos se capturan suficiente información sobre el pasado más reciente de los diferentes sensores y actuadores.\n",
    "- **h = 10**: Se establece un valor mayor que uno debido a que las redes neuronales tienden a reproducir el último valor cuando el horizonte de predicción es cercano a la entrada.\n",
    "- **m = 1**: Solo interesa predecir el siguiente valor, por lo que lo se deja a uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b36a6b",
   "metadata": {
    "papermill": {
     "duration": 0.069355,
     "end_time": "2025-05-27T04:28:49.487822",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.418467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 120  #tamaño de la ventana\n",
    "h = 10   #horizonte de predicción\n",
    "m = 1    #número de predicciones futuras\n",
    "\n",
    "#creación de los datasets\n",
    "train_dataset = TimeSeriesDataset(X_train, n, h, m)\n",
    "val_dataset = TimeSeriesDataset(X_validation, n, h, m)\n",
    "\n",
    "#creación de los dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=2,      #para cargar los datos más rápido\n",
    "    pin_memory=True     #optimiza la transferencia de los datos a la GPU\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    num_workers=2,      #para cargar los datos más rápido\n",
    "    pin_memory=True     #optimiza la transferencia de los datos a la GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a29b1c",
   "metadata": {
    "papermill": {
     "duration": 0.01002,
     "end_time": "2025-05-27T04:28:49.508864",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.498844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>2.2. Buscar los mejores hiperparámetros</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf95e5",
   "metadata": {
    "papermill": {
     "duration": 0.009159,
     "end_time": "2025-05-27T04:28:49.528170",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.519011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una vez elegido el modelo y establecidos los hiperparámetros de los datos de entrada, se debe entrenar y hacer fine-tuning al modelo. En este caso, se realizará:\n",
    "\n",
    "- **Grid Search**: Realiza una búsqueda exhaustiva en la que se prueban todas las posibles configuraciones de hiperparámetros y se queda con la mejor combinación. Es muy costosa en cuanto a tiempo pero asegura los mejores resultados dentro de los hiperparámetros definidos.\n",
    "\n",
    "Para comprobar que tan buenas son estas configuraciones, se utilizará el **MAE (Mean Absolute Error)**, ya que el modelo usará este tipo de error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08cd22",
   "metadata": {
    "papermill": {
     "duration": 0.009171,
     "end_time": "2025-05-27T04:28:49.546611",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.537440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A continuación, se muestran los pasos necesarios para realizar el **Grid Search** correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1130c7",
   "metadata": {
    "papermill": {
     "duration": 0.009239,
     "end_time": "2025-05-27T04:28:49.565096",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.555857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Primero se instalan las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82973546",
   "metadata": {
    "papermill": {
     "duration": 0.014377,
     "end_time": "2025-05-27T04:28:49.589377",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.575000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1c022",
   "metadata": {
    "papermill": {
     "duration": 0.009358,
     "end_time": "2025-05-27T04:28:49.608081",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.598723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se crea la función para construir el modelo. Algo que se debe tener en cuenta es que se usan capas LSTM en este problema de detección de anomalías con serires temporales por las siguientes razones:\n",
    "\n",
    "- Las Redes Densas o RNNs estándar no pueden recordar información muy antigua debido al problema de <u>desvanecimiento del gradiente</u>.\n",
    "\n",
    "- Las celdas de las **LSTM (Long Short-Term Memory)** presentan puertas que permiten recordar información mucho más anterior que en una recurrente, consiguiendo capturar mejores patrones de largo plazo. Además, evita el problema de desvanecimiento del gradiente.\n",
    "\n",
    "- las celdas LSTM presentan mejor resultado que las GRU (Gated Recurrent Units), ya que son una versión simplifiada de las LSTM, aunque son más rápidas. Se prefiere obtener mejor rendimiento a pesar de un mayor coste de entrenamiento.\n",
    "\n",
    "\n",
    "La siguiente clase recibe como parámetro la cantidad de capas y neuronas por capa LSTM y capa densa, además de la función de activación correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ccd7047",
   "metadata": {
    "papermill": {
     "duration": 0.018355,
     "end_time": "2025-05-27T04:28:49.635959",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.617604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "        def __init__(self, input_size, lstm_neurons, dense_neurons, activation, output_size):\n",
    "            super(LSTMPredictor, self).__init__()\n",
    "    \n",
    "            self.lstm_layers = nn.ModuleList()\n",
    "            self.dense_layers = nn.ModuleList()\n",
    "    \n",
    "            activations = {\n",
    "                'relu': nn.ReLU(),\n",
    "                'sigmoid': nn.Sigmoid()\n",
    "            }\n",
    "            self.activation = activations.get(activation, nn.ReLU())  # ReLU por defecto\n",
    "    \n",
    "            #para agregar las capas LSTM\n",
    "            for i in range(len(lstm_neurons)):\n",
    "                input_dim = input_size if i == 0 else lstm_neurons[i-1]\n",
    "                self.lstm_layers.append(nn.LSTM(input_dim, lstm_neurons[i], batch_first=True))\n",
    "    \n",
    "            #para agregar las capas densas\n",
    "            for i in range(len(dense_neurons)):\n",
    "                input_dim = lstm_neurons[-1] if i == 0 else dense_neurons[i-1]\n",
    "                self.dense_layers.append(nn.Linear(input_dim, dense_neurons[i]))\n",
    "    \n",
    "            #para generar la capa de salida\n",
    "            self.output_layer = nn.Linear(dense_neurons[-1], output_size)\n",
    "\n",
    "            #guardar la media, la desviación estándar y los errores en validación\n",
    "            self.register_buffer(\"train_mean\", torch.tensor(0.0))\n",
    "            self.register_buffer(\"train_std\", torch.tensor(1.0))\n",
    "            self.register_buffer(\"val_errors\", torch.tensor([]))\n",
    "    \n",
    "        def forward(self, x):\n",
    "            #pasa por las capas LSTM\n",
    "            for lstm in self.lstm_layers:\n",
    "                x, _ = lstm(x)\n",
    "            #se toma el último estado\n",
    "            x = x[:, -1, :]\n",
    "    \n",
    "            #pasa por las capas densas\n",
    "            for dense in self.dense_layers:\n",
    "                x = self.activation(dense(x))\n",
    "            #capa de salida\n",
    "            x = self.output_layer(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0fd4c",
   "metadata": {
    "papermill": {
     "duration": 0.009735,
     "end_time": "2025-05-27T04:28:49.655588",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.645853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A su vez, se crea la función para instanciar la clase del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558ebe83",
   "metadata": {
    "papermill": {
     "duration": 0.014867,
     "end_time": "2025-05-27T04:28:49.679781",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.664914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_size, lstm_neurons, dense_neurons, activation, output_size):\n",
    "    \"\"\"\n",
    "    build_model: Construye un modelo LSTM en PyTorch para regresión de series temporales.\n",
    "\n",
    "    Parámetros:\n",
    "        input_size: Número de características de entrada, es un entero.\n",
    "        lstm_neurons: Lista con el número de neuronas en cada capa LSTM, es una lista.\n",
    "        dense_neurons: Lista con el número de neuronas en cada capa densa, es una lista.\n",
    "        activation: Función de activación de las capas densas ('relu', 'sigmoid'), es una lista.\n",
    "        output_size: Número de características de salida, es un entero.\n",
    "\n",
    "    Devuelve:\n",
    "        Modelo preparado para entrenar.\n",
    "    \"\"\"\n",
    "    return LSTMPredictor(input_size, lstm_neurons, dense_neurons, activation, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cdfa4",
   "metadata": {
    "papermill": {
     "duration": 0.009252,
     "end_time": "2025-05-27T04:28:49.698496",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.689244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "El siguiente paso a realizar es configurar el espacio de búsqueda de hiperparámetros. Para ello, se crear un diccionario en el que vamos a establecer:\n",
    "\n",
    "- Número de nueronas por capa LSTM. Se comprueba si es mejor con 2 o 3 capas.\n",
    "- Número de neuronas por capa densa. Se comprueba si es mejor con 1 o 2 capas.\n",
    "- Función de activación. Se utiliza la función de activación ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1187e77",
   "metadata": {
    "papermill": {
     "duration": 0.009089,
     "end_time": "2025-05-27T04:28:49.806528",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.797439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finalmente se crea el código para realizar el **Grid Search**. Se explica detalladamente como funciona en el archivo de Python `grid_search.py`. Los resultados de este se pueden apreciar en el `README` de la carpeta de **Resultados**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b209b4f3",
   "metadata": {
    "papermill": {
     "duration": 1.148466,
     "end_time": "2025-05-27T04:28:50.964318",
     "exception": false,
     "start_time": "2025-05-27T04:28:49.815852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2e4b9",
   "metadata": {
    "papermill": {
     "duration": 0.009094,
     "end_time": "2025-05-27T04:28:51.084886",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.075792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una vez conocida la mejor combinación de capas LSTM y capas densas, se crea el diccionario para poder entrenar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fd9895c",
   "metadata": {
    "papermill": {
     "duration": 0.013941,
     "end_time": "2025-05-27T04:28:51.108218",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.094277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_grid = {\n",
    "    'lstm_neurons': [200, 130],\n",
    "    'dense_neurons': [256],\n",
    "    'activation': 'relu',\n",
    "    'epochs': 6 #6 epochs de entrenamiento para el modelo\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd355e",
   "metadata": {
    "papermill": {
     "duration": 0.009134,
     "end_time": "2025-05-27T04:28:51.126802",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.117668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>2.3. Entrenar el modelo</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a44ad",
   "metadata": {
    "papermill": {
     "duration": 0.009145,
     "end_time": "2025-05-27T04:28:51.145277",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.136132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una vez completados los pasos anteriores, es momento de entrenar el modelo. A continuación, se explican los pasos necesarios para ello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d746fa2",
   "metadata": {
    "papermill": {
     "duration": 0.009109,
     "end_time": "2025-05-27T04:28:51.163791",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.154682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Al igual que para hacer el grid search, se debe crear el generador de datos para el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11409d1f",
   "metadata": {
    "papermill": {
     "duration": 0.04881,
     "end_time": "2025-05-27T04:28:51.221908",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.173098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creación del dataset para el conjunto de test\n",
    "test_dataset = TimeSeriesDataset(X_test, n, h, m)\n",
    "\n",
    "#dataloader para los datos de test\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    num_workers=2,      #para cargar los datos más rápido\n",
    "    pin_memory=True     #optimiza la transferencia de los datos a la GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb119e",
   "metadata": {
    "papermill": {
     "duration": 0.009093,
     "end_time": "2025-05-27T04:28:51.243369",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.234276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Antes de poder entrenar, se debe crear una función auxiliar para calcular el error durante el proceso. Para calcular el error entre el resultado predicho por la red nueronal $\\hat{y}$ y el valor real en el dataset $y$ se usa el valor absoluto:\n",
    "\n",
    "$e = \\left| y - \\hat{y} \\right|$\n",
    "\n",
    "Dicha tarea la cumple la función **computa_error**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94185bed",
   "metadata": {
    "papermill": {
     "duration": 0.015716,
     "end_time": "2025-05-27T04:28:51.268899",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.253183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computa_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    computa_error: Calcula el error absoluto entre las predicciones y los valores verdaderos.\n",
    "\n",
    "    Parámetros:\n",
    "    y_true: Vector que contien los valores reales del dataset, es un array de NumPy.\n",
    "    y_pred: Vector que contiene las predicciones realiadas por la red neuronal, es un array de NumPy.\n",
    "    \n",
    "    Devuelve:\n",
    "        -error absoluto entre el vector de predicciones y el de valores reales.\n",
    "    \"\"\"\n",
    "    error = torch.abs(y_true - y_pred).detach().cpu().numpy() #error por variable\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2726e8",
   "metadata": {
    "papermill": {
     "duration": 0.009222,
     "end_time": "2025-05-27T04:28:51.287453",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.278231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una vez los datos ya están preparados y la configuración del modelo está lista, es momento de crear la función que se encargará de entrenar el modelo. Se explica cada paso mediante los comentarios en el código correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849bfb74",
   "metadata": {
    "papermill": {
     "duration": 0.014362,
     "end_time": "2025-05-27T04:28:51.311664",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.297302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler\n",
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96403cde",
   "metadata": {
    "papermill": {
     "duration": 0.018893,
     "end_time": "2025-05-27T04:28:51.339917",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.321024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(build_model, best_grid, train_loader, val_loader, output_size, device='cpu'):\n",
    "    \"\"\"\n",
    "    train_model: Función que entrena el modelo de detección de anomalías en Pytorch y que guarda dicho modelo.\n",
    "\n",
    "    Parámetros:\n",
    "    build_model: Función diseñada para construir el modelo de forma dinámica. Recibe la lista con las neuronas\n",
    "    correspondientes y devuelve el modelo, es una función.\n",
    "    best_grid: Diccionario que contiene la mejor combinación de hiperparámetros, es un diccionario.\n",
    "    train_loader: Es el DataLoader creado para cargar los datos de entrenamiento, es un DataLoader.\n",
    "    val_loader: Es el DataLoader creado para cargar los datos de validación, es un DataLoader.\n",
    "    output_size: Es el tamaño de la capa de salida, es un entero.\n",
    "    device='cpu': Dispositivo dónde se entrena el modelo, por defecto es la cpu.\n",
    "    \n",
    "    Devuelve:\n",
    "        Entrena el modelo y guarda checkpoints en las épocas 2,4,5,6 y el modelo final.\n",
    "    \"\"\"\n",
    "    #obtener un batch de los datos de train loader\n",
    "    X_sample, _ = next(iter(train_loader))\n",
    "    #establecer el tamaño de la entrada de la red a la cantidad\n",
    "    #de columnas del dataset, al igual que en la función\n",
    "    #del grid_search\n",
    "    input_size = X_sample.shape[2]\n",
    "\n",
    "    #crear el modelo con la función build_model y el diccionario\n",
    "    #de best_params\n",
    "    model = build_model(\n",
    "            input_size=input_size,\n",
    "            lstm_neurons=best_grid['lstm_neurons'],\n",
    "            dense_neurons=best_grid['dense_neurons'],\n",
    "            activation=best_grid['activation'],\n",
    "            output_size=output_size\n",
    "    ).to(device)\n",
    "\n",
    "    #utilizar el optimizador Adam con learning rate 0.0001\n",
    "    #para evitar el problea de explosión de gradiente\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    #establecer que la función de pérdida a usar\n",
    "    #es el error absoluto medio (MAE)\n",
    "    loss_fn = nn.L1Loss()\n",
    "    scaler = GradScaler(device='cuda')\n",
    "    \n",
    "    #realizar tantas épocas como indique el diccionario best_grid\n",
    "    for epoch in range(best_grid['epochs']):\n",
    "        #activar el modo de entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0 #inicializar la pérdida\n",
    "        train_errors = [] #lista para errores del train\n",
    "        #progress_bar para tener un pco más de información durante el entrenamiento\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{best_grid['epochs']}\",\n",
    "                            leave=False, mininterval=10)\n",
    "\n",
    "        #para todos los batches durante esta época, convertir los datos a float32 para\n",
    "        #que el entrenamiento sea más rápido\n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            #resetear los gradientes para realizar el entrenamiento\n",
    "            #en la epoch actual\n",
    "            optimizer.zero_grad()\n",
    "            #obtener las predicciones del modelo\n",
    "            with autocast(device_type='cuda'):\n",
    "                y_pred = model(X_batch)\n",
    "                y_batch = y_batch.view(y_batch.shape[0], -1)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            #usar el scaler para backpropagation\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            #aumentar la pérdida del entrenamiento\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            #actualizar la barra de progreso\n",
    "            #progress_bar.set_postfix(loss=f\"{train_loss / len(train_loader):.4f}\")\n",
    "        print(f\"Epoch {epoch + 1}/{best_grid['epochs']} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        \n",
    "        #para guardar resultados\n",
    "        if epoch + 1 <= 10:\n",
    "            train_errors, val_errors = evalua_y_guarda_results(model, train_loader, val_loader, device)\n",
    "            # Guardar estadísticas de entrenamiento y el modelo final\n",
    "            model.train_mean = torch.tensor(np.mean(train_errors)).to(device)\n",
    "            model.train_std = torch.tensor(np.std(train_errors)).to(device)\n",
    "            model.val_errors = torch.tensor(val_errors).to(device)\n",
    "            model_path = f\"model_epoch_{epoch + 1}.pt\"\n",
    "            scripted_model = torch.jit.script(model)\n",
    "            torch.jit.save(scripted_model, model_path)\n",
    "            print(f\"Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad6d9f",
   "metadata": {
    "papermill": {
     "duration": 0.009182,
     "end_time": "2025-05-27T04:28:51.358415",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.349233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Para considerar un registro como anomalía, se utilizarán umbrales basados en Z-Scores con los datos de validación. Para calcularlos, se deben realizar los siguientes pasos:\n",
    "\n",
    "\n",
    "1. Calcular la **Media** y la **Desviación Estándar** de los errores del conjunto de entrenamiento.\n",
    "\n",
    "2. Calcular los **Z-Scores** con los errores de validación. Para ello, se utiliza la siguiente fórmula:\n",
    "\n",
    "   $z_e = \\frac{e_v - \\mu_e}{\\sigma_e}$\n",
    "\n",
    "  Siendo $\\mu_e$ la media del error en los datos de entrenamiento y $\\sigma_e$ la desviación estándar en los datos de entrenamiento.\n",
    "\n",
    "Una vez calculamos los Z-Scores en validación, toca definir un umbral para decidir si se trata de una anomalía o no. En este caso, se calcula un umbral por característica a partir máximo del Z-Score calculado en validación. Si para una muestra en el test tiene mayor Score al umbral anterior, se considerará anomalía.\n",
    "\n",
    "Para evitar que se carguen más datos en la evaluación, se integran la **Media** del train, la **Desviación Estándar** del train y los **Errores** de validación en el modelo. Esta tarea la realiza la función **evalua_y_guarda_results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc8441f",
   "metadata": {
    "papermill": {
     "duration": 0.017413,
     "end_time": "2025-05-27T04:28:51.385357",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.367944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evalua_y_guarda_results(model, train_loader, val_loader, device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    evalua_y_guarda_results: Calcula los errores en la última epoch tanto para train como para validación.\n",
    "\n",
    "    Parámetros\n",
    "        model: Modelo sobre el que se quieren guardar los datos. Es un modelo de torch.\n",
    "        train_loader: Es el DataLoader creado para cargar los datos de entrenamiento, es un DataLoader.\n",
    "        val_loader: Es el DataLoader creado para cargar los datos de validación, es un DataLoader.\n",
    "        device='cpu': Dispositivo dónde se entrena el modelo, por defecto es la cpu.\n",
    "        \n",
    "    \n",
    "    Devuelve:\n",
    "        -train_errors: Lista de errores del train, es un array de NumPy.\n",
    "        -val_errors_tensor: Lista de errores de validación, es un tensor de torch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    train_errors = []\n",
    "    print(\"Calculando los errores en el entrenamiento...\")\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=\"Calculando errores en entrenamiento\", leave= False, mininterval=10):\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            y_pred = model(X_batch)\n",
    "            error = computa_error(y_batch, y_pred)\n",
    "            train_errors.append(error)\n",
    "    \n",
    "    train_errors = np.concatenate(train_errors, axis = 0)\n",
    "    print(\"Calculando los errores en validación...\")\n",
    "    val_errors = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=\"Calculando errores en validación\", leave= False, mininterval=10):\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            y_pred = model(X_batch)\n",
    "            error = computa_error(y_batch, y_pred)\n",
    "            error_tensor = torch.tensor(error).to(device)  #convertir el error a tensor de PyTorch\n",
    "            val_errors.append(error_tensor)\n",
    "\n",
    "    #concatenar todos los errores de validación\n",
    "    val_errors_tensor = torch.cat(val_errors, dim=0)\n",
    "\n",
    "    return train_errors, val_errors_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e84497",
   "metadata": {
    "papermill": {
     "duration": 0.009265,
     "end_time": "2025-05-27T04:28:51.404302",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.395037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se llama a la función para entrenar el modelo. En este caso, se cambia el parámetro `device=\"cuda\"` para entrenar más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3d5f456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T04:28:52.006093Z",
     "iopub.status.busy": "2025-05-27T04:28:52.005838Z",
     "iopub.status.idle": "2025-05-27T11:09:11.412397Z",
     "shell.execute_reply": "2025-05-27T11:09:11.411382Z"
    },
    "papermill": {
     "duration": 24019.417914,
     "end_time": "2025-05-27T11:09:11.413709",
     "exception": false,
     "start_time": "2025-05-27T04:28:51.995795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 - Train Loss: 0.0104\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1230516913.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model.val_errors = torch.tensor(val_errors).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6 - Train Loss: 0.0090\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6 - Train Loss: 0.0087\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6 - Train Loss: 0.0084\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6 - Train Loss: 0.0077\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6 - Train Loss: 0.0070\n",
      "Calculando los errores en el entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando los errores en validación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: model_epoch_6.pt\n"
     ]
    }
   ],
   "source": [
    "train_model(build_model, best_grid, train_loader, val_loader, X_train.shape[1], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764b5c7",
   "metadata": {
    "papermill": {
     "duration": 0.109316,
     "end_time": "2025-05-27T11:09:11.632619",
     "exception": false,
     "start_time": "2025-05-27T11:09:11.523303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>3. Evaluación del modelo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591f2cb",
   "metadata": {
    "papermill": {
     "duration": 0.109065,
     "end_time": "2025-05-27T11:09:11.849147",
     "exception": false,
     "start_time": "2025-05-27T11:09:11.740082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ahora es momento de evaluar el modelo entrenado. Para ello, se utiliza la función **evaluate_model**, y se explica con los comentarios cómo funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e4aec0d",
   "metadata": {
    "papermill": {
     "duration": 0.122501,
     "end_time": "2025-05-27T11:09:12.082175",
     "exception": false,
     "start_time": "2025-05-27T11:09:11.959674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, test_loader, y_test_true, device='cuda'):\n",
    "    \"\"\"\n",
    "    evaluate_model: Obtiene los resultados del modelo con los datos del test cargando los errores de\n",
    "    train y validación guardados en el modelo.\n",
    "    \n",
    "    Parámetros:\n",
    "    model_path: Ruta para cargar el modelo a evualuar, es una string.    \n",
    "    test_loader: Es el DataLoader que hemos creado para cargar los datos de test, es un DataLoader.\n",
    "    y_test_true: Vector que contiene los valores de la etiqueta clase de los datos de test, es un vector de NumPy.\n",
    "\n",
    "    Devuelve:\n",
    "        df_results: DataFrame con la salida del modelo (con las filas predichas), es un DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    #cargar el modelo guardado\n",
    "    model = torch.jit.load(model_path, map_location=device)\n",
    "    print(f\"Modelo cargado desde {model_path}\")\n",
    "    \n",
    "    #activar el modo de evaluación\n",
    "    model.eval()\n",
    "    \n",
    "    #se lee la media la s.d. guardados en el modelo\n",
    "    train_mean = model.train_mean.cpu().numpy()\n",
    "    train_std = model.train_std.cpu().numpy()\n",
    "    val_errors = model.val_errors.cpu().numpy()\n",
    "\n",
    "\n",
    "    #calcular los z-score en el conjunto de validación\n",
    "    val_z_scores = (val_errors - train_mean) / train_std\n",
    "\n",
    "    #definir el umbral para detectar anomalías: el máximo\n",
    "    feature_thresholds = np.max(val_z_scores, axis=0)#umbral por variable\n",
    "\n",
    "    #definir array vacío para los errores en el test\n",
    "    test_errors = []\n",
    "    test_predictions = []\n",
    "    y_test_real = []\n",
    "    #desactivar el cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(test_loader):\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            y_batch = y_batch.to(device).float()\n",
    "            y_pred = model(X_batch)\n",
    "            #calcular el error en el test con la función computa_error\n",
    "            error = computa_error(y_batch, y_pred)\n",
    "            test_errors.append(error)\n",
    "            test_predictions.append(y_pred.cpu().numpy()) #guardar predicciones\n",
    "            y_test_real.append(y_batch.cpu().numpy())\n",
    "            \n",
    "    #concatenar todos los errores de test\n",
    "    test_errors = np.concatenate(test_errors, axis=0)\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    y_test_real = np.concatenate(y_test_real, axis=0)\n",
    "    print(f\"Longitud de test_errors: {len(test_errors)}\")\n",
    "\n",
    "    #Calcular el z-score en el conjunto de prueba\n",
    "    test_z_scores = (test_errors - train_mean) / train_std\n",
    "\n",
    "    #detectar las anomalías usando el umbral definido en validación\n",
    "    anomalies_por_feature = test_z_scores > feature_thresholds #matriz de anomalias\n",
    "\n",
    "    #crear un array con las variables que causaron anomalía por fila\n",
    "    anomalies_list = [np.where(row)[0].tolist() if row.any() else [] for row in anomalies_por_feature]\n",
    "\n",
    "    #convertir la detección de anomalías a binario (si alguna variable es anomalía, la fila es anomalía)\n",
    "    anomalies = anomalies_por_feature.any(axis=1).astype(int)\n",
    "\n",
    "    print(f\"Anomalías detectadas en el conjunto de prueba: {np.sum(anomalies)}\")\n",
    "\n",
    "    #ajustar dimensiones\n",
    "    min_length = min(len(anomalies), len(y_test_true), len(test_predictions))\n",
    "    anomalies = anomalies[:min_length]\n",
    "    anomalies_list = anomalies_list[:min_length]\n",
    "    y_test_true = y_test_true[:min_length]\n",
    "    test_predictions = test_predictions[:min_length]\n",
    "    y_test_real = y_test_real[:min_length]\n",
    "\n",
    "    print(f\"Shape corregido de anomalies: {len(anomalies)}\")\n",
    "    print(f\"Shape corregido de y_test_true: {len(y_test_true)}\")\n",
    "\n",
    "    #crear un DataFrame con los resultados\n",
    "    df_results = pd.DataFrame({\n",
    "        'Predicción': list(test_predictions),  #guardar las predicciones del modelo\n",
    "        'Anomalía': anomalies,  #1 si es anomalía, 0 si es normal\n",
    "        'Variables_Anómalas': anomalies_list  #lista de variables que causan la anomalía\n",
    "    })\n",
    "    #llamar a la función calcula_metricas para conocer el redimiento del modelo\n",
    "    print(\"Calculando métricas de rendimiento para el conjunto de prueba...\")\n",
    "    calcula_metricas(y_test_true, anomalies)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a033f",
   "metadata": {
    "papermill": {
     "duration": 0.107446,
     "end_time": "2025-05-27T11:09:12.298707",
     "exception": false,
     "start_time": "2025-05-27T11:09:12.191261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Para poder evaluar el modelo, se deben usar diferentes métricas de evaluación. En este caso, hay que conocer que\n",
    "\n",
    "- **Precisión**: Esta métrica ayuda a conocer si el modelo tiene muchos falsos positivos.\n",
    "- **Recall**: Esta métrica indica el número de anomalías predichas por el modelo en función de las anomalías totales.\n",
    "\n",
    "Se busca un equilibrio entre dichas métricas y nos fijaremos en el **F1-Score**. \n",
    "También se muestra el accuracy y la matriz de confusión para tener más información. De este paso se ocupará la función **calcula_metricas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb736a2a",
   "metadata": {
    "papermill": {
     "duration": 0.521795,
     "end_time": "2025-05-27T11:09:12.928506",
     "exception": false,
     "start_time": "2025-05-27T11:09:12.406711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a8b3dad",
   "metadata": {
    "papermill": {
     "duration": 0.115523,
     "end_time": "2025-05-27T11:09:13.153778",
     "exception": false,
     "start_time": "2025-05-27T11:09:13.038255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcula_metricas(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    calcula_metricas: Calcula e imprime las métricas de Precision, Recall, F1-Score, Accuracy y la matriz de confusión.\n",
    "\n",
    "    Parámetros:\n",
    "    true_labels: Etiquetas reales de anomalías (1 para anomalía, 0 para normal), es un vector.\n",
    "    predicted_labels: Etiquetas predichas por el modelo (1 para anomalía, 0 para normal), es un vector.\n",
    "\n",
    "    Devuelve:\n",
    "        -precision: Precisión del modelo.\n",
    "        -recal: Recall del modelo.\n",
    "        -f1: F1-Score del modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    #para imprimir la matriz de confusión\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"Anomalía\"], yticklabels=[\"Normal\", \"Anomalía\"])\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Valor Real\")\n",
    "    plt.title(\"Matriz de Confusión\")\n",
    "    plt.show()\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4564a",
   "metadata": {
    "papermill": {
     "duration": 0.108606,
     "end_time": "2025-05-27T11:09:13.370530",
     "exception": false,
     "start_time": "2025-05-27T11:09:13.261924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "El modelo no predecirá hasta pasados los primeros 130 segundos. Para poder comparar los resultados reales, hay que quitar dichos registros en la etiqueta predictora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1a23417",
   "metadata": {
    "papermill": {
     "duration": 0.116904,
     "end_time": "2025-05-27T11:09:13.595046",
     "exception": false,
     "start_time": "2025-05-27T11:09:13.478142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real =y_test.values[130:]\n",
    "y_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8ebfa",
   "metadata": {
    "papermill": {
     "duration": 0.109762,
     "end_time": "2025-05-27T11:09:13.813545",
     "exception": false,
     "start_time": "2025-05-27T11:09:13.703783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se llama a la función **evaluate_model** para evaluar el rendimiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11aca273",
   "metadata": {
    "papermill": {
     "duration": 0.113806,
     "end_time": "2025-05-27T11:09:14.035566",
     "exception": false,
     "start_time": "2025-05-27T11:09:13.921760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde model_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 449789/449789 [12:10<00:00, 615.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de test_errors: 449789\n",
      "Anomalías detectadas en el conjunto de prueba: 60603\n",
      "Shape corregido de anomalies: 449789\n",
      "Shape corregido de y_test_true: 449789\n",
      "Calculando métricas de rendimiento para el conjunto de prueba...\n",
      "Precision: 0.6805\n",
      "Recall: 0.7550\n",
      "F1-Score: 0.7158\n",
      "Accuracy: 0.9272\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados = evaluate_model(\"model_epoch_6.pt\",test_loader,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec2dd4",
   "metadata": {
    "papermill": {
     "duration": 0.108628,
     "end_time": "2025-05-27T11:09:14.360001",
     "exception": false,
     "start_time": "2025-05-27T11:09:14.251373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>4. Exportar resultados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63666129",
   "metadata": {
    "papermill": {
     "duration": 0.109305,
     "end_time": "2025-05-27T11:09:14.578319",
     "exception": false,
     "start_time": "2025-05-27T11:09:14.469014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una vez entrenado y evaluado el modelo, es momento de exportar los resultados de las predicciones del modelo. Se realizan las transformaciones correspondientes al DataFrame devuelto por la función **evaluate_model** para que tenga un formato más legible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddc6ad",
   "metadata": {
    "papermill": {
     "duration": 0.111661,
     "end_time": "2025-05-27T11:09:14.800507",
     "exception": false,
     "start_time": "2025-05-27T11:09:14.688846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se muestra el formato del DataFrame devuelto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ecbe416",
   "metadata": {
    "papermill": {
     "duration": 0.114773,
     "end_time": "2025-05-27T11:09:15.022116",
     "exception": false,
     "start_time": "2025-05-27T11:09:14.907343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicción</th>\n",
       "      <th>Anomalía</th>\n",
       "      <th>Variables_Anómalas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.8674234, 0.17414367, 0.9756517, 0.94993854,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.8684834, 0.17328873, 0.97632176, 0.95126814...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8718623, 0.17345837, 0.9781587, 0.9542827, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.8745762, 0.17338717, 0.9796381, 0.95655334,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.88145113, 0.17322809, 0.9806627, 0.9578209,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449784</th>\n",
       "      <td>[0.87339485, 0.17098877, 0.9796256, 0.95657915...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449785</th>\n",
       "      <td>[0.8725362, 0.17086312, 0.9791974, 0.955965, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449786</th>\n",
       "      <td>[0.8709346, 0.17064169, 0.9783793, 0.95469505,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449787</th>\n",
       "      <td>[0.86974514, 0.17054108, 0.97777486, 0.9537713...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449788</th>\n",
       "      <td>[0.86964834, 0.17052719, 0.9777464, 0.9537134,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449789 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Predicción  Anomalía  \\\n",
       "0       [0.8674234, 0.17414367, 0.9756517, 0.94993854,...         0   \n",
       "1       [0.8684834, 0.17328873, 0.97632176, 0.95126814...         0   \n",
       "2       [0.8718623, 0.17345837, 0.9781587, 0.9542827, ...         0   \n",
       "3       [0.8745762, 0.17338717, 0.9796381, 0.95655334,...         0   \n",
       "4       [0.88145113, 0.17322809, 0.9806627, 0.9578209,...         0   \n",
       "...                                                   ...       ...   \n",
       "449784  [0.87339485, 0.17098877, 0.9796256, 0.95657915...         0   \n",
       "449785  [0.8725362, 0.17086312, 0.9791974, 0.955965, 0...         0   \n",
       "449786  [0.8709346, 0.17064169, 0.9783793, 0.95469505,...         0   \n",
       "449787  [0.86974514, 0.17054108, 0.97777486, 0.9537713...         0   \n",
       "449788  [0.86964834, 0.17052719, 0.9777464, 0.9537134,...         0   \n",
       "\n",
       "       Variables_Anómalas  \n",
       "0                      []  \n",
       "1                      []  \n",
       "2                      []  \n",
       "3                      []  \n",
       "4                      []  \n",
       "...                   ...  \n",
       "449784                 []  \n",
       "449785                 []  \n",
       "449786                 []  \n",
       "449787                 []  \n",
       "449788                 []  \n",
       "\n",
       "[449789 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bf38d9f",
   "metadata": {
    "papermill": {
     "duration": 0.116422,
     "end_time": "2025-05-27T11:09:15.247515",
     "exception": false,
     "start_time": "2025-05-27T11:09:15.131093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_0</th>\n",
       "      <th>Pred_1</th>\n",
       "      <th>Pred_2</th>\n",
       "      <th>Pred_3</th>\n",
       "      <th>Pred_4</th>\n",
       "      <th>Pred_5</th>\n",
       "      <th>Pred_6</th>\n",
       "      <th>Pred_7</th>\n",
       "      <th>Pred_8</th>\n",
       "      <th>Pred_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pred_34</th>\n",
       "      <th>Pred_35</th>\n",
       "      <th>Pred_36</th>\n",
       "      <th>Pred_37</th>\n",
       "      <th>Pred_38</th>\n",
       "      <th>Pred_39</th>\n",
       "      <th>Pred_40</th>\n",
       "      <th>Pred_41</th>\n",
       "      <th>Anomalía</th>\n",
       "      <th>Variables_Anómalas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867423</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.949939</td>\n",
       "      <td>0.853789</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>0.063017</td>\n",
       "      <td>0.058943</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>0.986914</td>\n",
       "      <td>-0.004249</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.978778</td>\n",
       "      <td>1.001349</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.868483</td>\n",
       "      <td>0.173289</td>\n",
       "      <td>0.976322</td>\n",
       "      <td>0.951268</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>-0.007442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.980064</td>\n",
       "      <td>1.002021</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.173458</td>\n",
       "      <td>0.978159</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.860965</td>\n",
       "      <td>0.944892</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>0.990406</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>1.003372</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.874576</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.956553</td>\n",
       "      <td>0.864572</td>\n",
       "      <td>0.948062</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>0.062957</td>\n",
       "      <td>0.068579</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>0.992103</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.984614</td>\n",
       "      <td>1.004434</td>\n",
       "      <td>-0.002298</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.881451</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0.980663</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.866907</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>-0.007851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>1.005093</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449784</th>\n",
       "      <td>0.873395</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.979626</td>\n",
       "      <td>0.956579</td>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.945684</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>0.069692</td>\n",
       "      <td>-0.008163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.004543</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449785</th>\n",
       "      <td>0.872536</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>0.979197</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>0.864462</td>\n",
       "      <td>0.944706</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>-0.008152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.992113</td>\n",
       "      <td>-0.004773</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.984379</td>\n",
       "      <td>1.004262</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449786</th>\n",
       "      <td>0.870935</td>\n",
       "      <td>0.170642</td>\n",
       "      <td>0.978379</td>\n",
       "      <td>0.954695</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.942696</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>-0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>-0.004747</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.983315</td>\n",
       "      <td>1.003691</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449787</th>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.170541</td>\n",
       "      <td>0.977775</td>\n",
       "      <td>0.953771</td>\n",
       "      <td>0.861113</td>\n",
       "      <td>0.941306</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.063444</td>\n",
       "      <td>0.066651</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.982534</td>\n",
       "      <td>1.003271</td>\n",
       "      <td>-0.002216</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449788</th>\n",
       "      <td>0.869648</td>\n",
       "      <td>0.170527</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>0.953713</td>\n",
       "      <td>0.861051</td>\n",
       "      <td>0.941224</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.982491</td>\n",
       "      <td>1.003250</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449789 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_0    Pred_1    Pred_2    Pred_3    Pred_4    Pred_5    Pred_6  \\\n",
       "0       0.867423  0.174144  0.975652  0.949939  0.853789  0.939187 -0.001590   \n",
       "1       0.868483  0.173289  0.976322  0.951268  0.856305  0.940386 -0.001524   \n",
       "2       0.871862  0.173458  0.978159  0.954283  0.860965  0.944892 -0.001444   \n",
       "3       0.874576  0.173387  0.979638  0.956553  0.864572  0.948062 -0.001378   \n",
       "4       0.881451  0.173228  0.980663  0.957821  0.866907  0.950570 -0.001363   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449784  0.873395  0.170989  0.979626  0.956579  0.865370  0.945684 -0.001352   \n",
       "449785  0.872536  0.170863  0.979197  0.955965  0.864462  0.944706 -0.001366   \n",
       "449786  0.870935  0.170642  0.978379  0.954695  0.862533  0.942696 -0.001397   \n",
       "449787  0.869745  0.170541  0.977775  0.953771  0.861113  0.941306 -0.001421   \n",
       "449788  0.869648  0.170527  0.977746  0.953713  0.861051  0.941224 -0.001422   \n",
       "\n",
       "          Pred_7    Pred_8    Pred_9  ...   Pred_34   Pred_35   Pred_36  \\\n",
       "0       0.063017  0.058943 -0.007066  ... -0.000270 -0.001250  0.986914   \n",
       "1       0.063159  0.062008 -0.007442  ... -0.000348 -0.001302  0.988267   \n",
       "2       0.063063  0.065727 -0.007670  ... -0.000387 -0.001367  0.990406   \n",
       "3       0.062957  0.068579 -0.007847  ... -0.000451 -0.001425  0.992103   \n",
       "4       0.062968  0.070138 -0.007851  ... -0.000534 -0.001508  0.993231   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "449784  0.063220  0.069692 -0.008163  ... -0.000470 -0.001477  0.992523   \n",
       "449785  0.063287  0.069101 -0.008152  ... -0.000455 -0.001464  0.992113   \n",
       "449786  0.063374  0.067697 -0.008096  ... -0.000434 -0.001437  0.991256   \n",
       "449787  0.063444  0.066651 -0.008048  ... -0.000414 -0.001416  0.990621   \n",
       "449788  0.063458  0.066600 -0.008044  ... -0.000415 -0.001415  0.990599   \n",
       "\n",
       "         Pred_37   Pred_38   Pred_39   Pred_40   Pred_41  Anomalía  \\\n",
       "0      -0.004249  0.012097  0.978778  1.001349 -0.002178         0   \n",
       "1      -0.004401  0.012046  0.980064  1.002021 -0.002192         0   \n",
       "2      -0.004487  0.011558  0.982634  1.003372 -0.002253         0   \n",
       "3      -0.004586  0.011192  0.984614  1.004434 -0.002298         0   \n",
       "4      -0.004658  0.010972  0.985832  1.005093 -0.002384         0   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "449784 -0.004786  0.011193  0.984896  1.004543 -0.002278         0   \n",
       "449785 -0.004773  0.011311  0.984379  1.004262 -0.002264         0   \n",
       "449786 -0.004747  0.011540  0.983315  1.003691 -0.002236         0   \n",
       "449787 -0.004721  0.011708  0.982534  1.003271 -0.002216         0   \n",
       "449788 -0.004723  0.011724  0.982491  1.003250 -0.002215         0   \n",
       "\n",
       "        Variables_Anómalas  \n",
       "0                       []  \n",
       "1                       []  \n",
       "2                       []  \n",
       "3                       []  \n",
       "4                       []  \n",
       "...                    ...  \n",
       "449784                  []  \n",
       "449785                  []  \n",
       "449786                  []  \n",
       "449787                  []  \n",
       "449788                  []  \n",
       "\n",
       "[449789 rows x 44 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(df_resultados[\"Predicción\"].to_list(), columns=[f\"Pred_{i}\" for i in range(len(df_resultados[\"Predicción\"][0]))])\n",
    "\n",
    "#concatenar con el DataFrame original\n",
    "salida_modelo = pd.concat([ pred_df, df_resultados[[\"Anomalía\", \"Variables_Anómalas\"]]], axis=1)\n",
    "salida_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "206dac69",
   "metadata": {
    "papermill": {
     "duration": 0.112338,
     "end_time": "2025-05-27T11:09:15.465115",
     "exception": false,
     "start_time": "2025-05-27T11:09:15.352777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>std_FIT101_120</th>\n",
       "      <th>std_LIT101_120</th>\n",
       "      <th>std_FIT201_120</th>\n",
       "      <th>...</th>\n",
       "      <th>MV303_2</th>\n",
       "      <th>MV304_0</th>\n",
       "      <th>MV304_1</th>\n",
       "      <th>MV304_2</th>\n",
       "      <th>P302_1</th>\n",
       "      <th>P302_2</th>\n",
       "      <th>P602_1</th>\n",
       "      <th>P602_2</th>\n",
       "      <th>Anomalía</th>\n",
       "      <th>Variables_Anómalas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867423</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.949939</td>\n",
       "      <td>0.853789</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>0.063017</td>\n",
       "      <td>0.058943</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>0.986914</td>\n",
       "      <td>-0.004249</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.978778</td>\n",
       "      <td>1.001349</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.868483</td>\n",
       "      <td>0.173289</td>\n",
       "      <td>0.976322</td>\n",
       "      <td>0.951268</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>-0.007442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.980064</td>\n",
       "      <td>1.002021</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.173458</td>\n",
       "      <td>0.978159</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.860965</td>\n",
       "      <td>0.944892</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>0.990406</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>1.003372</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.874576</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.956553</td>\n",
       "      <td>0.864572</td>\n",
       "      <td>0.948062</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>0.062957</td>\n",
       "      <td>0.068579</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>0.992103</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.984614</td>\n",
       "      <td>1.004434</td>\n",
       "      <td>-0.002298</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.881451</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0.980663</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.866907</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>-0.007851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>1.005093</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449784</th>\n",
       "      <td>0.873395</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.979626</td>\n",
       "      <td>0.956579</td>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.945684</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>0.069692</td>\n",
       "      <td>-0.008163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.004543</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449785</th>\n",
       "      <td>0.872536</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>0.979197</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>0.864462</td>\n",
       "      <td>0.944706</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>-0.008152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.992113</td>\n",
       "      <td>-0.004773</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.984379</td>\n",
       "      <td>1.004262</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449786</th>\n",
       "      <td>0.870935</td>\n",
       "      <td>0.170642</td>\n",
       "      <td>0.978379</td>\n",
       "      <td>0.954695</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.942696</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>-0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>-0.004747</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.983315</td>\n",
       "      <td>1.003691</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449787</th>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.170541</td>\n",
       "      <td>0.977775</td>\n",
       "      <td>0.953771</td>\n",
       "      <td>0.861113</td>\n",
       "      <td>0.941306</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.063444</td>\n",
       "      <td>0.066651</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.982534</td>\n",
       "      <td>1.003271</td>\n",
       "      <td>-0.002216</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449788</th>\n",
       "      <td>0.869648</td>\n",
       "      <td>0.170527</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>0.953713</td>\n",
       "      <td>0.861051</td>\n",
       "      <td>0.941224</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.982491</td>\n",
       "      <td>1.003250</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449789 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101    FIT201   DPIT301    LIT301    LIT401    FIT601  \\\n",
       "0       0.867423  0.174144  0.975652  0.949939  0.853789  0.939187 -0.001590   \n",
       "1       0.868483  0.173289  0.976322  0.951268  0.856305  0.940386 -0.001524   \n",
       "2       0.871862  0.173458  0.978159  0.954283  0.860965  0.944892 -0.001444   \n",
       "3       0.874576  0.173387  0.979638  0.956553  0.864572  0.948062 -0.001378   \n",
       "4       0.881451  0.173228  0.980663  0.957821  0.866907  0.950570 -0.001363   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449784  0.873395  0.170989  0.979626  0.956579  0.865370  0.945684 -0.001352   \n",
       "449785  0.872536  0.170863  0.979197  0.955965  0.864462  0.944706 -0.001366   \n",
       "449786  0.870935  0.170642  0.978379  0.954695  0.862533  0.942696 -0.001397   \n",
       "449787  0.869745  0.170541  0.977775  0.953771  0.861113  0.941306 -0.001421   \n",
       "449788  0.869648  0.170527  0.977746  0.953713  0.861051  0.941224 -0.001422   \n",
       "\n",
       "        std_FIT101_120  std_LIT101_120  std_FIT201_120  ...   MV303_2  \\\n",
       "0             0.063017        0.058943       -0.007066  ... -0.000270   \n",
       "1             0.063159        0.062008       -0.007442  ... -0.000348   \n",
       "2             0.063063        0.065727       -0.007670  ... -0.000387   \n",
       "3             0.062957        0.068579       -0.007847  ... -0.000451   \n",
       "4             0.062968        0.070138       -0.007851  ... -0.000534   \n",
       "...                ...             ...             ...  ...       ...   \n",
       "449784        0.063220        0.069692       -0.008163  ... -0.000470   \n",
       "449785        0.063287        0.069101       -0.008152  ... -0.000455   \n",
       "449786        0.063374        0.067697       -0.008096  ... -0.000434   \n",
       "449787        0.063444        0.066651       -0.008048  ... -0.000414   \n",
       "449788        0.063458        0.066600       -0.008044  ... -0.000415   \n",
       "\n",
       "         MV304_0   MV304_1   MV304_2    P302_1    P302_2    P602_1    P602_2  \\\n",
       "0      -0.001250  0.986914 -0.004249  0.012097  0.978778  1.001349 -0.002178   \n",
       "1      -0.001302  0.988267 -0.004401  0.012046  0.980064  1.002021 -0.002192   \n",
       "2      -0.001367  0.990406 -0.004487  0.011558  0.982634  1.003372 -0.002253   \n",
       "3      -0.001425  0.992103 -0.004586  0.011192  0.984614  1.004434 -0.002298   \n",
       "4      -0.001508  0.993231 -0.004658  0.010972  0.985832  1.005093 -0.002384   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449784 -0.001477  0.992523 -0.004786  0.011193  0.984896  1.004543 -0.002278   \n",
       "449785 -0.001464  0.992113 -0.004773  0.011311  0.984379  1.004262 -0.002264   \n",
       "449786 -0.001437  0.991256 -0.004747  0.011540  0.983315  1.003691 -0.002236   \n",
       "449787 -0.001416  0.990621 -0.004721  0.011708  0.982534  1.003271 -0.002216   \n",
       "449788 -0.001415  0.990599 -0.004723  0.011724  0.982491  1.003250 -0.002215   \n",
       "\n",
       "        Anomalía  Variables_Anómalas  \n",
       "0              0                  []  \n",
       "1              0                  []  \n",
       "2              0                  []  \n",
       "3              0                  []  \n",
       "4              0                  []  \n",
       "...          ...                 ...  \n",
       "449784         0                  []  \n",
       "449785         0                  []  \n",
       "449786         0                  []  \n",
       "449787         0                  []  \n",
       "449788         0                  []  \n",
       "\n",
       "[449789 rows x 44 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un diccionario de mapeo entre los nombres Pred_X y los nombres originales\n",
    "mapeo_nombres = {f\"Pred_{i}\": X_train.columns[i] for i in range(42)}\n",
    "\n",
    "#renombrar las columnas usando el diccionario\n",
    "salida_modelo.rename(columns=mapeo_nombres, inplace=True)\n",
    "salida_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1066113",
   "metadata": {
    "papermill": {
     "duration": 0.115371,
     "end_time": "2025-05-27T11:09:15.687977",
     "exception": false,
     "start_time": "2025-05-27T11:09:15.572606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nombres_variables = salida_modelo.columns[:-2].tolist()\n",
    "\n",
    "#convertir los índices en nombres\n",
    "salida_modelo[\"Variables_Anómalas\"] = salida_modelo[\"Variables_Anómalas\"].apply(lambda indices: [nombres_variables[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d5c71d1",
   "metadata": {
    "papermill": {
     "duration": 0.114062,
     "end_time": "2025-05-27T11:09:15.918190",
     "exception": false,
     "start_time": "2025-05-27T11:09:15.804128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>std_FIT101_120</th>\n",
       "      <th>std_LIT101_120</th>\n",
       "      <th>std_FIT201_120</th>\n",
       "      <th>...</th>\n",
       "      <th>MV303_2</th>\n",
       "      <th>MV304_0</th>\n",
       "      <th>MV304_1</th>\n",
       "      <th>MV304_2</th>\n",
       "      <th>P302_1</th>\n",
       "      <th>P302_2</th>\n",
       "      <th>P602_1</th>\n",
       "      <th>P602_2</th>\n",
       "      <th>Anomalía</th>\n",
       "      <th>Variables_Anómalas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867423</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.949939</td>\n",
       "      <td>0.853789</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>0.063017</td>\n",
       "      <td>0.058943</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>0.986914</td>\n",
       "      <td>-0.004249</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.978778</td>\n",
       "      <td>1.001349</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.868483</td>\n",
       "      <td>0.173289</td>\n",
       "      <td>0.976322</td>\n",
       "      <td>0.951268</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>-0.007442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.980064</td>\n",
       "      <td>1.002021</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.173458</td>\n",
       "      <td>0.978159</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.860965</td>\n",
       "      <td>0.944892</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>0.990406</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>1.003372</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.874576</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.956553</td>\n",
       "      <td>0.864572</td>\n",
       "      <td>0.948062</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>0.062957</td>\n",
       "      <td>0.068579</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>0.992103</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.984614</td>\n",
       "      <td>1.004434</td>\n",
       "      <td>-0.002298</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.881451</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0.980663</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.866907</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>-0.007851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.993231</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>1.005093</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449784</th>\n",
       "      <td>0.873395</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.979626</td>\n",
       "      <td>0.956579</td>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.945684</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>0.069692</td>\n",
       "      <td>-0.008163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.004543</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449785</th>\n",
       "      <td>0.872536</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>0.979197</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>0.864462</td>\n",
       "      <td>0.944706</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.069101</td>\n",
       "      <td>-0.008152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.992113</td>\n",
       "      <td>-0.004773</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.984379</td>\n",
       "      <td>1.004262</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449786</th>\n",
       "      <td>0.870935</td>\n",
       "      <td>0.170642</td>\n",
       "      <td>0.978379</td>\n",
       "      <td>0.954695</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.942696</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>-0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>-0.004747</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.983315</td>\n",
       "      <td>1.003691</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449787</th>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.170541</td>\n",
       "      <td>0.977775</td>\n",
       "      <td>0.953771</td>\n",
       "      <td>0.861113</td>\n",
       "      <td>0.941306</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.063444</td>\n",
       "      <td>0.066651</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.982534</td>\n",
       "      <td>1.003271</td>\n",
       "      <td>-0.002216</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449788</th>\n",
       "      <td>0.869648</td>\n",
       "      <td>0.170527</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>0.953713</td>\n",
       "      <td>0.861051</td>\n",
       "      <td>0.941224</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.982491</td>\n",
       "      <td>1.003250</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449789 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101    FIT201   DPIT301    LIT301    LIT401    FIT601  \\\n",
       "0       0.867423  0.174144  0.975652  0.949939  0.853789  0.939187 -0.001590   \n",
       "1       0.868483  0.173289  0.976322  0.951268  0.856305  0.940386 -0.001524   \n",
       "2       0.871862  0.173458  0.978159  0.954283  0.860965  0.944892 -0.001444   \n",
       "3       0.874576  0.173387  0.979638  0.956553  0.864572  0.948062 -0.001378   \n",
       "4       0.881451  0.173228  0.980663  0.957821  0.866907  0.950570 -0.001363   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449784  0.873395  0.170989  0.979626  0.956579  0.865370  0.945684 -0.001352   \n",
       "449785  0.872536  0.170863  0.979197  0.955965  0.864462  0.944706 -0.001366   \n",
       "449786  0.870935  0.170642  0.978379  0.954695  0.862533  0.942696 -0.001397   \n",
       "449787  0.869745  0.170541  0.977775  0.953771  0.861113  0.941306 -0.001421   \n",
       "449788  0.869648  0.170527  0.977746  0.953713  0.861051  0.941224 -0.001422   \n",
       "\n",
       "        std_FIT101_120  std_LIT101_120  std_FIT201_120  ...   MV303_2  \\\n",
       "0             0.063017        0.058943       -0.007066  ... -0.000270   \n",
       "1             0.063159        0.062008       -0.007442  ... -0.000348   \n",
       "2             0.063063        0.065727       -0.007670  ... -0.000387   \n",
       "3             0.062957        0.068579       -0.007847  ... -0.000451   \n",
       "4             0.062968        0.070138       -0.007851  ... -0.000534   \n",
       "...                ...             ...             ...  ...       ...   \n",
       "449784        0.063220        0.069692       -0.008163  ... -0.000470   \n",
       "449785        0.063287        0.069101       -0.008152  ... -0.000455   \n",
       "449786        0.063374        0.067697       -0.008096  ... -0.000434   \n",
       "449787        0.063444        0.066651       -0.008048  ... -0.000414   \n",
       "449788        0.063458        0.066600       -0.008044  ... -0.000415   \n",
       "\n",
       "         MV304_0   MV304_1   MV304_2    P302_1    P302_2    P602_1    P602_2  \\\n",
       "0      -0.001250  0.986914 -0.004249  0.012097  0.978778  1.001349 -0.002178   \n",
       "1      -0.001302  0.988267 -0.004401  0.012046  0.980064  1.002021 -0.002192   \n",
       "2      -0.001367  0.990406 -0.004487  0.011558  0.982634  1.003372 -0.002253   \n",
       "3      -0.001425  0.992103 -0.004586  0.011192  0.984614  1.004434 -0.002298   \n",
       "4      -0.001508  0.993231 -0.004658  0.010972  0.985832  1.005093 -0.002384   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449784 -0.001477  0.992523 -0.004786  0.011193  0.984896  1.004543 -0.002278   \n",
       "449785 -0.001464  0.992113 -0.004773  0.011311  0.984379  1.004262 -0.002264   \n",
       "449786 -0.001437  0.991256 -0.004747  0.011540  0.983315  1.003691 -0.002236   \n",
       "449787 -0.001416  0.990621 -0.004721  0.011708  0.982534  1.003271 -0.002216   \n",
       "449788 -0.001415  0.990599 -0.004723  0.011724  0.982491  1.003250 -0.002215   \n",
       "\n",
       "        Anomalía  Variables_Anómalas  \n",
       "0              0                  []  \n",
       "1              0                  []  \n",
       "2              0                  []  \n",
       "3              0                  []  \n",
       "4              0                  []  \n",
       "...          ...                 ...  \n",
       "449784         0                  []  \n",
       "449785         0                  []  \n",
       "449786         0                  []  \n",
       "449787         0                  []  \n",
       "449788         0                  []  \n",
       "\n",
       "[449789 rows x 44 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a547b0",
   "metadata": {
    "papermill": {
     "duration": 0.109155,
     "end_time": "2025-05-27T11:09:16.137521",
     "exception": false,
     "start_time": "2025-05-27T11:09:16.028366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Se guarad el modelo como `.csv` de manera local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5e0678f",
   "metadata": {
    "papermill": {
     "duration": 0.113711,
     "end_time": "2025-05-27T11:09:16.358791",
     "exception": false,
     "start_time": "2025-05-27T11:09:16.245080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "salida_modelo.to_csv(\"salida_modelo.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7517129,
     "sourceId": 11956040,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24049.452434,
   "end_time": "2025-05-27T11:09:20.806273",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-27T04:28:31.353839",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
