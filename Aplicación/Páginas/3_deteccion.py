import streamlit as st
import pandas as pd
import time
import torch
import numpy as np
from torch.utils.data import Dataset
from datetime import datetime
from PIL import Image 
import matplotlib.pyplot as plt



 

 ########################################################
 #GENERADOR DE DATOS
 ########################################################
class TimeSeriesDataset(Dataset):
    def __init__(self, data, n, h, m, overlap = 1):
        """
        Par치metros:
            data: Serie temporal, es un DataFrame.
            n: Tama침o de la ventana, es un entero.
            h: Horizonte de predicci칩n, es un entero.
            m: N칰mero de predicciones futuras, es un entero.
        """

        #lo converitmos a float32 para que el entrenamiento sea m치s r치pido
        if isinstance(data, np.ndarray):
            self.data = torch.tensor(data, dtype=torch.float32)
        else:
            self.data = torch.tensor(data.values, dtype=torch.float32)

        self.n = n
        self.h = h
        self.m = m
        self.overlap = overlap
        
        #cantidad de muestras posibles del dataset
        self.num_samples = (len(self.data) - (n + h + m) + 1)// self.overlap

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        """
        getitem: Devuelve la muestra correspondiente al 칤ndice dado.

        Devuelve:
            - x: ventana de tama침o n.
            - y: un valor futuro despu칠s de un horizonte h (tama침o 1).
        """
        real_idx = idx*self.overlap
        #ventana de entrada de tama침o n, con lo que se entrena
        x = self.data[real_idx:real_idx+self.n]

        #queremos predecir el valor[n+m+h], por lo que lo comparamos con el real
        y = self.data[real_idx+self.n+self.h:real_idx+self.n+self.h+self.m].reshape(-1)

        return x, y
    


 ########################################################
 #EVALUACION DEL MODELO
 ########################################################
def computa_error(y_true, y_pred):
    """
    computa_error: Calcula el error absoluto entre las predicciones y los valores verdaderos.

    Par치metros:
    y_true: Vector que contien los valores reales del dataset, es un array de NumPy.
    y_pred: Vector que contiene las predicciones realiadas por la red neuronal, es un array de NumPy.
    
    Devuelve:
        -error absoluto entre el vector de predicciones y el de valores reales.
    """
    error = torch.abs(y_true - y_pred).detach().cpu().numpy() #error por variable, no se hace la media
    return error

def evaluate_model(model_path, test_loader, y_test_true, X_test, device='cpu'):
    """
    evaluate_model: Obtiene los errores con los datos de entrenamiento, calcula el umbral con los datos
    de validaci칩n y obtiene los resultados del modelo con los datos del test.
    
    Par치metros:
    model_path: ruta para cargar el modelo a evualuar.    
    test_loader: Es el DataLoader que hemos creado para cargar los datos de test, es un DataLoader.
    y_test_true: Vector que contiene los valores de la etiqueta clase de los datos de test, es un vector de NumPy.


    modificaci칩n 20 marzo 2025:
    -elimino el c치lculo de la media y s.d. de error del train ya que ahora se calcula durante el entrenamiento.
    -elimino el c치lculo de val_errors y lo a침ado en el entrenamiento.
    
    """
    #cargamos el modelo guardado
    model = torch.jit.load(model_path, map_location=device)
    print(f"Modelo cargado desde {model_path}")
    
    #activamos el modo de evaluaci칩n
    model.eval()
    
    #nuevo 20/03/2025:
    #se lee la media la s.d. guardados en el modelo
    train_mean = model.train_mean.cpu().numpy()
    train_std = model.train_std.cpu().numpy()
    val_errors = model.val_errors.cpu().numpy()


    #calculamos los z-score en el conjunto de validaci칩n
    val_z_scores = (val_errors - train_mean) / train_std

    #definimos el umbral para detectar anomal칤as: percentil 99.5%
    feature_thresholds = np.max(val_z_scores, axis=0)#umbral por variable

    #en los datos de test, hacemos lo mismo
    #definimos array vac칤o para los errores en el test
    test_errors = []
    test_predictions = []
    y_test_real = []

    # Crear un DataFrame vac칤o para almacenar los resultados
    df_results = pd.DataFrame(columns=['Fecha', 'Predicci칩n', 'Anomal칤a', 'Variables An칩malas'])

    columns = ['Fecha', 'Anomal칤a', 'Detalles']
    anomaly_history_df = pd.DataFrame(columns=columns)

    # Crear un contenedor en Streamlit para la tabla
    table_placeholder = st.empty()

    # Inicializar el marcador de posici칩n para la imagen
    image_placeholder = st.empty()

    anomaly_message_placeholder = st.empty()  # Esto ser치 el placeholder para el mensaje

    # Crear un contenedor en Streamlit para la tabla
    table_placeholder_anomaly = st.empty()


    #desactivamos el c치lculo de gradientes
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch = X_batch.to(device).float()
            y_batch = y_batch.to(device).float()
            y_pred = model(X_batch)
            #calculamos el error en el test con la funci칩n computa_error
            error = computa_error(y_batch, y_pred)
            test_errors.append(error)
            test_predictions.append(y_pred.cpu().numpy()) #guardo predicciones
            y_test_real.append(y_batch.cpu().numpy())
            #time.sleep(0.8) #para la simulacion

            # Mostrar en Streamlit la predicci칩n actualizada
            # Detectar anomal칤as
            test_z_score = (error - train_mean) / train_std
            anomalies_per_feature = test_z_score > feature_thresholds
            # Crear una lista para almacenar los nombres de los sensores an칩malos
            anomaly_list = []

            # Iterar sobre cada fila (cada predicci칩n)
            for row in anomalies_per_feature:
                # Obtener los 칤ndices de las columnas donde hay anomal칤as (True)
                anomaly_indices = np.where(row)[0]  # Esto devolver치 todos los 칤ndices de caracter칤sticas an칩malas
                # Mapear los 칤ndices de las anomal칤as a los nombres de las caracter칤sticas (sensores)
                anomaly_list.append([X_test.columns[idx] for idx in anomaly_indices])  # Convertir 칤ndices en nombres de sensores

            anomaly_flag = int(anomalies_per_feature.any())
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')


            if anomaly_list:
                # Comprobar si el sensor 'FIT101' est치 en la lista de anomal칤as
                if 'FIT101' in anomaly_list[0]:  # Aqu칤, 'anomaly_list[0]' contiene los sensores an칩malos de la primera fila
                    state_image_path = "Im치genes/EstadoSistema/FIT101.png"  # Imagen cuando 'FIT101' tiene una anomal칤a
                elif 'LIT101' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/lIT101.png"  # Imagen cuando 'LIT101' tiene una anomal칤a
                elif 'DPIT301' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/DPIT301.png"  # Imagen cuando 'DPIT301' tiene una anomal칤a
                elif 'FIT201' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/FIT201.png"  # Imagen cuando 'FIT201' tiene una anomal칤a
                elif 'FIT601' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/FIT601.png"  # Imagen cuando 'FIT601' tiene una anomal칤a
                elif 'LIT301' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/LIT301.png"  # Imagen cuando 'LIT301' tiene una anomal칤a
                elif 'LIT401' in anomaly_list[0]:
                    state_image_path = "Im치genes/EstadoSistema/LIT401.png"  # Imagen cuando 'LIT401' tiene una anomal칤a
                elif any(sensor.startswith("MV101") for sensor in anomaly_list[0]):  # Detecta cualquier "MV101..."
                    state_image_path = "Im치genes/EstadoSistema/MV101.png"
                elif any(sensor.startswith("MV201") for sensor in anomaly_list[0]):  # Detecta cualquier "MV201..."
                    state_image_path = "Im치genes/EstadoSistema/MV201.png"
                elif any(sensor.startswith("MV301") for sensor in anomaly_list[0]):  # Detecta cualquier "MV301..."
                    state_image_path = "Im치genes/EstadoSistema/MV301.png"
                elif any(sensor.startswith("MV302") for sensor in anomaly_list[0]):  # Detecta cualquier "MV302..."
                    state_image_path = "Im치genes/EstadoSistema/MV302.png"
                elif any(sensor.startswith("MV303") for sensor in anomaly_list[0]):  # Detecta cualquier "MV303..."
                    state_image_path = "Im치genes/EstadoSistema/MV303.png"
                elif any(sensor.startswith("MV304") for sensor in anomaly_list[0]):  # Detecta cualquier "MV304..."
                    state_image_path = "Im치genes/EstadoSistema/MV304.png"
                elif any(sensor.startswith("P101") for sensor in anomaly_list[0]):  # Detecta cualquier "P101..."
                    state_image_path = "Im치genes/EstadoSistema/P101.png"
                elif any(sensor.startswith("P203") for sensor in anomaly_list[0]):  # Detecta cualquier "P203..."
                    state_image_path = "Im치genes/EstadoSistema/P203.png"
                elif any(sensor.startswith("P205") for sensor in anomaly_list[0]):  # Detecta cualquier "P205..."
                    state_image_path = "Im치genes/EstadoSistema/P205.png"
                elif any(sensor.startswith("P302") for sensor in anomaly_list[0]):  # Detecta cualquier "P302..."
                    state_image_path = "Im치genes/EstadoSistema/P302.png"
                elif any(sensor.startswith("P602") for sensor in anomaly_list[0]):  # Detecta cualquier "P602..."
                    state_image_path = "Im치genes/EstadoSistema/P602.png"
                else:
                    state_image_path = "Im치genes/EstadoSistema/Normal.png"  # Imagen cuando otro sensor tiene la anomal칤a
            else:
                state_image_path = "Im치genes/EstadoSistema/Normal.png"  # Imagen cuando no hay anomal칤as
            # Mostrar imagen del estado del sistema
            estado_sistema(state_image_path, image_placeholder) 

            # Agregar nueva predicci칩n a la tabla con nombres de sensores
            new_row = pd.DataFrame({
                'Fecha': [current_time],
                'Predicci칩n': [y_pred.cpu().numpy().tolist()],  # Convertir a lista para evitar errores de formato
                'Anomal칤a': ["S칤" if anomaly_flag == 1 else "No"],  # Convertir 1 -> "S칤" y 0 -> "No"
                'Variables An칩malas': anomaly_list  # Convertir 칤ndices a nombres de sensores
            })

            df_results = pd.concat([df_results, new_row], ignore_index=True)
            table_placeholder.dataframe(df_results, use_container_width=True)

            if anomaly_list[0]:
                # Mostrar el mensaje solo cuando hay una anomal칤a
                anomaly_message_placeholder.error("춰Anomal칤a detectada! Revisa los sensores y el estado del sistema.")
                
                alert_message = f"游뚿游뚿游뚿 REVISA LOS SENSORES: {', '.join(anomaly_list[0])}"

                # Crear una nueva fila con la informaci칩n de la predicci칩n y la anomal칤a detectada
                new_row = {
                    'Fecha': current_time,
                    'Anomal칤a': "S칤" if anomaly_flag == 1 else "No",  # Indicar si hay anomal칤a
                    'Detalles': alert_message  # Convertir las predicciones a lista
                }

                # Convertir el diccionario a un DataFrame de pandas
                new_row_df = pd.DataFrame([new_row])  # Convertimos el diccionario en un DataFrame

                # Agregar la nueva fila al DataFrame usando pd.concat
                anomaly_history_df = pd.concat([anomaly_history_df, new_row_df], ignore_index=True)

                # Mostrar el DataFrame actualizado con las anomal칤as
                table_placeholder_anomaly.dataframe(anomaly_history_df, use_container_width=True)
            else:
                # Si no hay anomal칤a, podemos borrar el mensaje de alerta
                anomaly_message_placeholder.empty()
                        


    return df_results

############################################
#MOSTRAR LA IMAGEN DE ESTADO DEL SISTEMA
############################################
def estado_sistema(path_imagen, image_placeholder):
    """
    Muestra una imagen que representa el estado del sistema en Streamlit.

    Par치metros:
    - state_image_path: Ruta de la imagen que representa el estado actual del sistema.
    """
    image = Image.open(path_imagen)  # Abre la imagen desde la ruta
    image_placeholder.image(image, caption="Estado del Sistema", use_container_width=True)

# Funci칩n para la p치gina de detecci칩n de anomal칤as
def mostrar_deteccion_anomalias():
    # Configuraci칩n de estilos
    st.markdown("""
    <style>
        .title {
            font-size: 36px !important;
            color: #1f77b4;
            text-align: center;
            margin-bottom: 20px;
            font-weight: bold;
        }
        .header {
            font-size: 24px !important;
            color: #2e8b57;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 2px solid #2e8b57;
            padding-bottom: 5px;
        }
        .upload-box {
            border: 2px dashed #1f77b4;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            margin: 20px 0;
            background-color: #f8f9fa;
        }
        .data-preview {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #f0f8ff;
        }
        .processing-box {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #fff4e6;
        }
        .result-box {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #f0fff0;
        }
        .anomaly {
            color: #d9534f;
            font-weight: bold;
        }
        .normal {
            color: #5cb85c;
            font-weight: bold;
        }
        .progress-container {
            margin: 20px 0;
        }
        .file-name {
            font-weight: bold;
            color: #1f77b4;
        }
        .emoji-container {
            text-align: center;
            font-size: 30px;
            margin: 10px 0 20px 0;
        }
    </style>
    """, unsafe_allow_html=True)

    # T칤tulo principal
    st.markdown('<div class="title">Detecci칩n de Anomal칤as en Tiempo Real</div>', unsafe_allow_html=True)
    st.markdown('<div class="emoji-container">游댌游돁</div>', unsafe_allow_html=True)
    
    # Secci칩n de carga de archivos
    st.markdown('<div class="header">游닋 Carga tus datos</div>', unsafe_allow_html=True)
    st.markdown("""
    <div class="upload-box">
        <p style="font-size: 18px;">Sube un archivo CSV con los datos de los sensores para analizar</p>
        <p style="font-size: 14px; color: #666;">Formatos soportados: .csv (m치x. 200MB)</p>
    </div>
    """, unsafe_allow_html=True)
    
    archivo = st.file_uploader("Selecciona un archivo", type=["csv"], label_visibility="collapsed")

    if archivo:
        # Mostrar nombre del archivo
        st.markdown(f'<div style="margin: 10px 0;">Archivo seleccionado: <span class="file-name">{archivo.name}</span></div>', unsafe_allow_html=True)
        
        # Cargar datos
        try:
            test = pd.read_csv(archivo)
            
            # Vista previa de datos
            st.markdown('<div class="header">游 Vista previa de los datos</div>', unsafe_allow_html=True)
            st.markdown("""
            <div class="data-preview">
                <p>Primeras 5 filas del dataset cargado:</p>
            </div>
            """, unsafe_allow_html=True)
            st.dataframe(test.head().style.set_properties(**{'background-color': '#f8f9fa'}), use_container_width=True)
            
            # Procesamiento en tiempo real
            st.markdown('<div class="header">丘뙖잺 Procesamiento en tiempo real</div>', unsafe_allow_html=True)
            st.markdown("""
            <div class="processing-box">
                <p>Analizando datos fila por fila con el modelo LSTM...</p>
            </div>
            """, unsafe_allow_html=True)
            

            X_test = test.drop(columns = "Normal/Attack")
            y_test = test["Normal/Attack"]

            #instanciar el generador de datos
            #creaci칩n de los datasets tanto para entrenamiento como para test
            test_dataset = TimeSeriesDataset(X_test, 120, 10, 1)

            #creaci칩n de los dataloaders


            #creamos el dataloader para los datos de test
            test_loader = torch.utils.data.DataLoader(
                test_dataset, 
                num_workers=0,      #para cargar los datos m치s r치pido
                pin_memory=True     #optimiza la transferencia de los datos a la GPU
            )

            y_real =y_test.values[130:]

            resultados_df = evaluate_model("Modelo/modelo_completo.pt",test_loader,y_real,X_test, device='cpu')
            
            # Bot칩n para descargar resultados
            csv = resultados_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="游닌 Descargar resultados",
                data=csv,
                file_name='resultados_anomalias.csv',
                mime='text/csv'
            )
            
        except Exception as e:
            st.error(f"Error al procesar el archivo: {str(e)}")

mostrar_deteccion_anomalias()