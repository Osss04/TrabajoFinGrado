import streamlit as st
import pandas as pd
import time
import torch
import numpy as np
from torch.utils.data import Dataset
from datetime import datetime
from PIL import Image 

 ########################################################
 #GENERADOR DE DATOS
 ########################################################
class TimeSeriesDataset(Dataset):
    def __init__(self, data, n, h, m, overlap = 1):
        """
        Par치metros:
            data: Serie temporal, es un DataFrame.
            n: Tama침o de la ventana, es un entero.
            h: Horizonte de predicci칩n, es un entero.
            m: N칰mero de predicciones futuras, es un entero.
        """

        #convertir a float32 para que el entrenamiento sea m치s r치pido
        if isinstance(data, np.ndarray):
            self.data = torch.tensor(data, dtype=torch.float32)
        else:
            self.data = torch.tensor(data.values, dtype=torch.float32)

        self.n = n
        self.h = h
        self.m = m
        self.overlap = overlap
        
        #cantidad de muestras posibles del dataset
        self.num_samples = (len(self.data) - (n + h + m) + 1)// self.overlap

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        """
        getitem: Devuelve la muestra correspondiente al 칤ndice dado.

        Devuelve:
            - x: ventana de tama침o n.
            - y: un valor futuro despu칠s de un horizonte h (tama침o 1).
        """
        real_idx = idx*self.overlap
        #ventana de entrada de tama침o n, con lo que se entrena
        x = self.data[real_idx:real_idx+self.n]

        #se quiere predecir el valor[n+m+h], por lo que se compara con el real
        y = self.data[real_idx+self.n+self.h:real_idx+self.n+self.h+self.m].reshape(-1)

        return x, y
    

 ########################################################
 #EVALUACION DEL MODELO
 ########################################################
def computa_error(y_true, y_pred):
    """
    computa_error: Calcula el error absoluto entre las predicciones y los valores verdaderos.

    Par치metros:
    y_true: Vector que contien los valores reales del dataset, es un array de NumPy.
    y_pred: Vector que contiene las predicciones realiadas por la red neuronal, es un array de NumPy.
    
    Devuelve:
        -error absoluto entre el vector de predicciones y el de valores reales.
    """
    error = torch.abs(y_true - y_pred).detach().cpu().numpy() #error por variable
    return error

def evaluate_model(model_path, test_loader, y_test_true, X_test, device='cpu'):
    """
    evaluate_model: Obtiene los errores con los datos de entrenamiento, calcula el umbral con los datos
    de validaci칩n y obtiene los resultados del modelo con los datos del test.
    
    Par치metros:
    model_path: ruta para cargar el modelo a evualuar. , es una string.  
    test_loader: Es el DataLoader que hemos creado para cargar los datos de test, es un DataLoader.
    y_test_true: Vector que contiene los valores de la etiqueta clase de los datos de test, es un vector de NumPy.
    
    """
    #cargar el modelo guardado
    model = torch.jit.load(model_path, map_location=device)
    print(f"Modelo cargado desde {model_path}")
    
    #activar el modo de evaluaci칩n
    model.eval()
    
    #se lee la media la s.d. guardados en el modelo
    train_mean = model.train_mean.cpu().numpy()
    train_std = model.train_std.cpu().numpy()
    val_errors = model.val_errors.cpu().numpy()


    #calcular los z-score en el conjunto de validaci칩n
    val_z_scores = (val_errors - train_mean) / train_std

    #definir el umbral para detectar anomal칤as: el m치ximo
    feature_thresholds = np.max(val_z_scores, axis=0)#umbral por variable

    #definir array vac칤o para los errores en el test
    test_errors = []
    test_predictions = []
    y_test_real = []

    #crear un DataFrame vac칤o para almacenar los resultados
    df_results = pd.DataFrame(columns=['游늱 Fecha', '游늳 Predicci칩n', '游뚿 Anomal칤a', '丘멆잺 Variables An칩malas'])

    columns = ['游늱 Fecha Anomal칤a', '丘멆잺 Variables An칩malas', '游늺 Desviaci칩n respecto al umbral']
    anomaly_history_df = pd.DataFrame(columns=columns)

    #crear un contenedor en Streamlit para la tabla
    table_placeholder = st.empty()

    #inicializar el marcador de posici칩n para la imagen
    image_placeholder = st.empty()

    anomaly_message_placeholder = st.empty()  #placeholder para el mensaje

    #contenedor en Streamlit para la tabla
    table_placeholder_anomaly = st.empty()

    #desactivar el c치lculo de gradientes
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch = X_batch.to(device).float()
            y_batch = y_batch.to(device).float()
            y_pred = model(X_batch)
            #calcular el error en el test con la funci칩n computa_error
            error = computa_error(y_batch, y_pred)
            test_errors.append(error)
            test_predictions.append(y_pred.cpu().numpy()) #guardar predicciones
            y_test_real.append(y_batch.cpu().numpy())
            time.sleep(1) #para la simulacion

            #mostrar en Streamlit la predicci칩n actualizada
            #detectar anomal칤as
            test_z_score = (error - train_mean) / train_std
            anomalies_per_feature = test_z_score > feature_thresholds
            #crear una lista para almacenar los nombres de los sensores an칩malos
            anomaly_list = []

            #iterar sobre cada fila (cada predicci칩n)
            for row in anomalies_per_feature:
                #obtener los 칤ndices de las columnas donde hay anomal칤as (True)
                anomaly_indices = np.where(row)[0]  # Esto devolver치 todos los 칤ndices de caracter칤sticas an칩malas
                #mapear los 칤ndices de las anomal칤as a los nombres de las caracter칤sticas (sensores)
                anomaly_list.append([X_test.columns[idx] for idx in anomaly_indices])  #convertir 칤ndices en nombres de sensores

            anomaly_flag = int(anomalies_per_feature.any())
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            #elegir imagen a mostrar en tiempo real
            state_image_path = elige_imagen(anomaly_list)
            #mostrar imagen del estado del sistema
            estado_sistema(state_image_path, image_placeholder) 

            #agregar nueva predicci칩n a la tabla con nombres de sensores
            new_row = pd.DataFrame({
                '游늱 Fecha': [current_time],
                '游늳 Predicci칩n': [np.round(y_pred.cpu().numpy(),4).tolist()],  #convertir a lista para evitar errores de formato
                '游뚿 Anomal칤a': ["S칤" if anomaly_flag == 1 else "No"],  #convertir 1 -> "S칤" y 0 -> "No"
                '丘멆잺 Variables An칩malas': anomaly_list  #convertir 칤ndices a nombres de sensores
            })

            df_results = pd.concat([df_results, new_row], ignore_index=True)
            df_results['游늳 Predicci칩n'] = df_results['游늳 Predicci칩n'].apply( #para aproximar la predicci칩n a dos decimales
            lambda x: np.round(np.array(x, dtype=float), 2).tolist()
            )
            table_placeholder.dataframe(df_results, use_container_width=True)

            if anomaly_list[0]:
                #mostrar el mensaje solo cuando hay una anomal칤a
                anomaly_message_placeholder.error("춰Anomal칤a detectada! Revisa los sensores y el estado del sistema.")
                
                errors_for_anomalies = error[0][anomaly_indices]

                thresholds_for_anomalies = feature_thresholds[anomaly_indices]  # Usamos el umbral m치s alto de los sensores

                mensajes_desvio = []

                #para poner un mensaje de cu치nto se desv칤a la anomal칤a del umbral de anomal칤as
                for sensor, error, umbral in zip(anomaly_list[0], errors_for_anomalies, thresholds_for_anomalies):
                    if umbral != 0:  #para evitar divisi칩n por cero
                        desviacion = (abs(error) / umbral) * 100
                        mensaje = f'El registro "{sensor}" se desv칤a un {desviacion:.2f}% del umbral'
                    else:
                        mensaje = f'El registro "{sensor}" tiene umbral cero (no se puede calcular desviaci칩n)'
                    mensajes_desvio.append(mensaje)

                #a침adir informaci칩n a la tabla de anomal칤as
                new_row = {
                    '游늱 Fecha Anomal칤a': current_time,
                    '丘멆잺 Variables An칩malas': anomaly_list,
                    '游늺 Desviaci칩n respecto al umbral': mensajes_desvio
                }

                #convertir el diccionario a un DataFrame de pandas
                new_row_df = pd.DataFrame([new_row])

                #agregar la nueva fila al DataFrame usando pd.concat
                anomaly_history_df = pd.concat([anomaly_history_df, new_row_df], ignore_index=True)

                #mostrar el DataFrame actualizado con las anomal칤as
                table_placeholder_anomaly.dataframe(anomaly_history_df, use_container_width=True)
            else:
                #si no hay anomal칤a, podemos borrar el mensaje de alerta
                anomaly_message_placeholder.empty()
                        


    return df_results

############################################
#MOSTRAR LA IMAGEN DE ESTADO DEL SISTEMA
############################################
def estado_sistema(path_imagen, image_placeholder):
    """
    estado_sistema: Muestra una imagen que representa el estado del sistema en Streamlit.

    Par치metros:
    state_image_path: Ruta de la imagen que representa el estado actual del sistema.
    image_placeholder: Placeholder del Streamlit d칩nde se actualiza la imagen.
    """
    image = Image.open(path_imagen)  #abre la imagen desde la ruta
    image_placeholder.image(image, caption="Estado del Sistema", use_container_width=True)

def elige_imagen(anomaly_list):
    """
    elige_imagen: En funci칩n de la anomal칤a, elige la imagen correspondiente.

    Par치metros:
    anomaly_list: Lista en la que aparecen los sensores an칩malos.

    Devuelve:
        state_image_path: Ruta a la imagen que toca mostrar en funci칩n de la lista de anomal칤as.
    """
    #si hay anomal칤a
    if anomaly_list:
        if 'FIT101' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/FIT101.png"  #imagen cuando 'FIT101' tiene una anomal칤a
        elif 'LIT101' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/lIT101.png"  #imagen cuando 'LIT101' tiene una anomal칤a
        elif 'DPIT301' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/DPIT301.png"  #imagen cuando 'DPIT301' tiene una anomal칤a
        elif 'FIT201' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/FIT201.png"  #imagen cuando 'FIT201' tiene una anomal칤a
        elif 'FIT601' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/FIT601.png"  #imagen cuando 'FIT601' tiene una anomal칤a
        elif 'LIT301' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/LIT301.png"  #imagen cuando 'LIT301' tiene una anomal칤a
        elif 'LIT401' in anomaly_list[0]:
            state_image_path = "Im치genes/EstadoSistema/LIT401.png"  #imagen cuando 'LIT401' tiene una anomal칤a
        elif any(sensor.startswith("MV101") for sensor in anomaly_list[0]):  #cualquier 'MV101'
            state_image_path = "Im치genes/EstadoSistema/MV101.png"
        elif any(sensor.startswith("MV201") for sensor in anomaly_list[0]):  #cualquier 'MV201'
            state_image_path = "Im치genes/EstadoSistema/MV201.png"
        elif any(sensor.startswith("MV301") for sensor in anomaly_list[0]):  #cualquier 'MV301'
            state_image_path = "Im치genes/EstadoSistema/MV301.png"
        elif any(sensor.startswith("MV302") for sensor in anomaly_list[0]):  #cualquier 'MV302'
            state_image_path = "Im치genes/EstadoSistema/MV302.png"
        elif any(sensor.startswith("MV303") for sensor in anomaly_list[0]):  #cualquier 'MV303'
            state_image_path = "Im치genes/EstadoSistema/MV303.png"
        elif any(sensor.startswith("MV304") for sensor in anomaly_list[0]):  #cualquier 'MV304'
            state_image_path = "Im치genes/EstadoSistema/MV304.png"
        elif any(sensor.startswith("P101") for sensor in anomaly_list[0]):  #cualquier 'P101'
            state_image_path = "Im치genes/EstadoSistema/P101.png"
        elif any(sensor.startswith("P203") for sensor in anomaly_list[0]):  #cualquier 'P203'
            state_image_path = "Im치genes/EstadoSistema/P203.png"
        elif any(sensor.startswith("P205") for sensor in anomaly_list[0]):  #cualquier 'P205'
            state_image_path = "Im치genes/EstadoSistema/P205.png"
        elif any(sensor.startswith("P302") for sensor in anomaly_list[0]):  #cualquier 'P302'
            state_image_path = "Im치genes/EstadoSistema/P302.png"
        elif any(sensor.startswith("P602") for sensor in anomaly_list[0]):  #cualquier 'P602'
            state_image_path = "Im치genes/EstadoSistema/P602.png"
        else:
            state_image_path = "Im치genes/EstadoSistema/Normal.png"  # Imagen cuando no hay anomal칤as
    return state_image_path

def mostrar_deteccion_anomalias():
    #configuraci칩n de estilos
    st.markdown("""
    <style>
        .title {
            font-size: 36px !important;
            color: #1f77b4;
            text-align: center;
            margin-bottom: 20px;
            font-weight: bold;
        }
        .header {
            font-size: 24px !important;
            color: #2e8b57;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 2px solid #2e8b57;
            padding-bottom: 5px;
        }
        .upload-box {
            border: 2px dashed #1f77b4;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            margin: 20px 0;
            background-color: #f8f9fa;
        }
        .data-preview {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #f0f8ff;
        }
        .processing-box {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #fff4e6;
        }
        .result-box {
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            background-color: #f0fff0;
        }
        .anomaly {
            color: #d9534f;
            font-weight: bold;
        }
        .normal {
            color: #5cb85c;
            font-weight: bold;
        }
        .progress-container {
            margin: 20px 0;
        }
        .file-name {
            font-weight: bold;
            color: #1f77b4;
        }
        .emoji-container {
            text-align: center;
            font-size: 30px;
            margin: 10px 0 20px 0;
        }
    </style>
    """, unsafe_allow_html=True)

    #t칤tulo
    st.markdown('<div class="title">Detecci칩n de Anomal칤as en Tiempo Real</div>', unsafe_allow_html=True)
    st.markdown('<div class="emoji-container">游댌游돁</div>', unsafe_allow_html=True)
    
    #cargar el test
    test = pd.read_csv("Datos/test_modificado.csv")

    st.markdown('<div class="header">游늵 Datos cargados</div>', unsafe_allow_html=True)
    st.markdown("""
    <div class="upload-box">
        <p style="font-size: 18px;">Los datos de los sensores ya han sido cargados.</p>
        <p style="font-size: 14px; color: #666;">Haz clic en el bot칩n para comenzar el an치lisis.</p>
    </div>
    """, unsafe_allow_html=True)
    
    #para poner el bot칩n en el centro
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        boton = st.button("游 Comenzar an치lisis", use_container_width=True)
    
    if boton:
        #vista previa de datos
        st.markdown('<div class="header">游 Vista previa de los datos</div>', unsafe_allow_html=True)
        st.markdown("""
        <div class="data-preview">
            <p>Primeras 5 filas del dataset de los sensores:</p>
        </div>
        """, unsafe_allow_html=True)
        st.dataframe(test.head().style.set_properties(**{'background-color': '#f8f9fa'}), use_container_width=True)
        st.success("Iniciando an치lisis del archivo...")
        try:
            #procesamiento en tiempo real
            st.markdown('<div class="header">丘뙖잺 Procesamiento en tiempo real</div>', unsafe_allow_html=True)
            st.markdown("""
            <div class="processing-box">
                <p>Analizando datos fila por fila con el modelo LSTM...</p>
            </div>
            """, unsafe_allow_html=True)
            

            X_test = test.drop(columns = "Normal/Attack")
            y_test = test["Normal/Attack"]

            #instanciar el generador de datos
            #creaci칩n de los datasets tanto para entrenamiento como para test
            test_dataset = TimeSeriesDataset(X_test, 120, 10, 1)

            #creaci칩n de los dataloaders


            #crear el dataloader para los datos de test
            test_loader = torch.utils.data.DataLoader(
                test_dataset, 
                num_workers=0,      #para cargar los datos m치s r치pido
                pin_memory=True     #optimiza la transferencia de los datos a la GPU
            )

            y_real =y_test.values[130:]

            resultados_df = evaluate_model("Modelo/modelo_completo.pt",test_loader,y_real,X_test, device='cpu')
            
            #bot칩n para descargar resultados
            csv = resultados_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="游닌 Descargar resultados",
                data=csv,
                file_name='resultados_anomalias.csv',
                mime='text/csv'
            )
            
        except Exception as e:
            st.error(f"Error al procesar el archivo: {str(e)}")

mostrar_deteccion_anomalias()